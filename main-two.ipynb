{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-25T16:26:28.106119Z","iopub.status.busy":"2024-09-25T16:26:28.105563Z","iopub.status.idle":"2024-09-25T16:26:29.383573Z","shell.execute_reply":"2024-09-25T16:26:29.382331Z","shell.execute_reply.started":"2024-09-25T16:26:28.106047Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:29.386064Z","iopub.status.busy":"2024-09-25T16:26:29.385573Z","iopub.status.idle":"2024-09-25T16:26:29.604512Z","shell.execute_reply":"2024-09-25T16:26:29.603262Z","shell.execute_reply.started":"2024-09-25T16:26:29.386031Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>File_Name</th>\n","      <th>Text</th>\n","      <th>Image_Path</th>\n","      <th>BERT_Embeddings</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10017</td>\n","      <td>The balcony juts out on the south side, with t...</td>\n","      <td>../floorplan_image\\10017.png</td>\n","      <td>[[-0.6216691, -0.029034398, 0.045137372, -0.09...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10042</td>\n","      <td>The balcony is in the southeastern corner of t...</td>\n","      <td>../floorplan_image\\10042.png</td>\n","      <td>[[-0.6944888, 0.015425202, -0.0041255075, -0.1...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10045</td>\n","      <td>bathroom is in north side of the house, next t...</td>\n","      <td>../floorplan_image\\10045.png</td>\n","      <td>[[-0.6030773, -0.0011889015, 0.045667697, -0.1...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10047</td>\n","      <td>The balcony is in the north east corner, just ...</td>\n","      <td>../floorplan_image\\10047.png</td>\n","      <td>[[-0.69215715, -0.052971497, 0.03891414, -0.02...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10052</td>\n","      <td>The balcony is on the southwest side of the ap...</td>\n","      <td>../floorplan_image\\10052.png</td>\n","      <td>[[-0.61126614, -0.005761562, -0.054692637, 0.0...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  File_Name                                               Text  \\\n","0     10017  The balcony juts out on the south side, with t...   \n","1     10042  The balcony is in the southeastern corner of t...   \n","2     10045  bathroom is in north side of the house, next t...   \n","3     10047  The balcony is in the north east corner, just ...   \n","4     10052  The balcony is on the southwest side of the ap...   \n","\n","                     Image_Path  \\\n","0  ../floorplan_image\\10017.png   \n","1  ../floorplan_image\\10042.png   \n","2  ../floorplan_image\\10045.png   \n","3  ../floorplan_image\\10047.png   \n","4  ../floorplan_image\\10052.png   \n","\n","                                     BERT_Embeddings  \n","0  [[-0.6216691, -0.029034398, 0.045137372, -0.09...  \n","1  [[-0.6944888, 0.015425202, -0.0041255075, -0.1...  \n","2  [[-0.6030773, -0.0011889015, 0.045667697, -0.1...  \n","3  [[-0.69215715, -0.052971497, 0.03891414, -0.02...  \n","4  [[-0.61126614, -0.005761562, -0.054692637, 0.0...  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["dataset_path = os.path.join('dataset', 'word_embeddings_dataframe.pkl')\n","df = pd.read_pickle(dataset_path) \n","df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:29.606581Z","iopub.status.busy":"2024-09-25T16:26:29.606196Z","iopub.status.idle":"2024-09-25T16:26:29.651398Z","shell.execute_reply":"2024-09-25T16:26:29.650134Z","shell.execute_reply.started":"2024-09-25T16:26:29.606550Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>File_Name</th>\n","      <th>Text</th>\n","      <th>Image_Path</th>\n","      <th>BERT_Embeddings</th>\n","      <th>Modified_Image_Path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10017</td>\n","      <td>The balcony juts out on the south side, with t...</td>\n","      <td>../floorplan_image\\10017.png</td>\n","      <td>[[-0.6216691, -0.029034398, 0.045137372, -0.09...</td>\n","      <td>human_annotated_images/10017.png</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10042</td>\n","      <td>The balcony is in the southeastern corner of t...</td>\n","      <td>../floorplan_image\\10042.png</td>\n","      <td>[[-0.6944888, 0.015425202, -0.0041255075, -0.1...</td>\n","      <td>human_annotated_images/10042.png</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10045</td>\n","      <td>bathroom is in north side of the house, next t...</td>\n","      <td>../floorplan_image\\10045.png</td>\n","      <td>[[-0.6030773, -0.0011889015, 0.045667697, -0.1...</td>\n","      <td>human_annotated_images/10045.png</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10047</td>\n","      <td>The balcony is in the north east corner, just ...</td>\n","      <td>../floorplan_image\\10047.png</td>\n","      <td>[[-0.69215715, -0.052971497, 0.03891414, -0.02...</td>\n","      <td>human_annotated_images/10047.png</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10052</td>\n","      <td>The balcony is on the southwest side of the ap...</td>\n","      <td>../floorplan_image\\10052.png</td>\n","      <td>[[-0.61126614, -0.005761562, -0.054692637, 0.0...</td>\n","      <td>human_annotated_images/10052.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  File_Name                                               Text  \\\n","0     10017  The balcony juts out on the south side, with t...   \n","1     10042  The balcony is in the southeastern corner of t...   \n","2     10045  bathroom is in north side of the house, next t...   \n","3     10047  The balcony is in the north east corner, just ...   \n","4     10052  The balcony is on the southwest side of the ap...   \n","\n","                     Image_Path  \\\n","0  ../floorplan_image\\10017.png   \n","1  ../floorplan_image\\10042.png   \n","2  ../floorplan_image\\10045.png   \n","3  ../floorplan_image\\10047.png   \n","4  ../floorplan_image\\10052.png   \n","\n","                                     BERT_Embeddings  \\\n","0  [[-0.6216691, -0.029034398, 0.045137372, -0.09...   \n","1  [[-0.6944888, 0.015425202, -0.0041255075, -0.1...   \n","2  [[-0.6030773, -0.0011889015, 0.045667697, -0.1...   \n","3  [[-0.69215715, -0.052971497, 0.03891414, -0.02...   \n","4  [[-0.61126614, -0.005761562, -0.054692637, 0.0...   \n","\n","                Modified_Image_Path  \n","0  human_annotated_images/10017.png  \n","1  human_annotated_images/10042.png  \n","2  human_annotated_images/10045.png  \n","3  human_annotated_images/10047.png  \n","4  human_annotated_images/10052.png  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Function to modify image path\n","def modify_image_path(image_path):\n","    filename = os.path.basename(image_path).split(\"floorplan_image\\\\\")[1]\n","    new_path = os.path.join(\"human_annotated_images\", filename)\n","    return new_path\n","\n","# Apply the function to the 'Image_Path' column in the DataFrame\n","df['Modified_Image_Path'] = df['Image_Path'].apply(modify_image_path)\n","\n","df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:29.654677Z","iopub.status.busy":"2024-09-25T16:26:29.653797Z","iopub.status.idle":"2024-09-25T16:26:29.668351Z","shell.execute_reply":"2024-09-25T16:26:29.667029Z","shell.execute_reply.started":"2024-09-25T16:26:29.654639Z"},"trusted":true},"outputs":[],"source":["df.drop(['Image_Path'], axis = 1, inplace = True)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:29.670430Z","iopub.status.busy":"2024-09-25T16:26:29.669913Z","iopub.status.idle":"2024-09-25T16:26:29.696949Z","shell.execute_reply":"2024-09-25T16:26:29.695844Z","shell.execute_reply.started":"2024-09-25T16:26:29.670384Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>File_Name</th>\n","      <th>Text</th>\n","      <th>BERT_Embeddings</th>\n","      <th>Image_Path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10017</td>\n","      <td>The balcony juts out on the south side, with t...</td>\n","      <td>[[-0.6216691, -0.029034398, 0.045137372, -0.09...</td>\n","      <td>human_annotated_images/10017.png</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10042</td>\n","      <td>The balcony is in the southeastern corner of t...</td>\n","      <td>[[-0.6944888, 0.015425202, -0.0041255075, -0.1...</td>\n","      <td>human_annotated_images/10042.png</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10045</td>\n","      <td>bathroom is in north side of the house, next t...</td>\n","      <td>[[-0.6030773, -0.0011889015, 0.045667697, -0.1...</td>\n","      <td>human_annotated_images/10045.png</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10047</td>\n","      <td>The balcony is in the north east corner, just ...</td>\n","      <td>[[-0.69215715, -0.052971497, 0.03891414, -0.02...</td>\n","      <td>human_annotated_images/10047.png</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10052</td>\n","      <td>The balcony is on the southwest side of the ap...</td>\n","      <td>[[-0.61126614, -0.005761562, -0.054692637, 0.0...</td>\n","      <td>human_annotated_images/10052.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  File_Name                                               Text  \\\n","0     10017  The balcony juts out on the south side, with t...   \n","1     10042  The balcony is in the southeastern corner of t...   \n","2     10045  bathroom is in north side of the house, next t...   \n","3     10047  The balcony is in the north east corner, just ...   \n","4     10052  The balcony is on the southwest side of the ap...   \n","\n","                                     BERT_Embeddings  \\\n","0  [[-0.6216691, -0.029034398, 0.045137372, -0.09...   \n","1  [[-0.6944888, 0.015425202, -0.0041255075, -0.1...   \n","2  [[-0.6030773, -0.0011889015, 0.045667697, -0.1...   \n","3  [[-0.69215715, -0.052971497, 0.03891414, -0.02...   \n","4  [[-0.61126614, -0.005761562, -0.054692637, 0.0...   \n","\n","                         Image_Path  \n","0  human_annotated_images/10017.png  \n","1  human_annotated_images/10042.png  \n","2  human_annotated_images/10045.png  \n","3  human_annotated_images/10047.png  \n","4  human_annotated_images/10052.png  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# removed image path folder\n","df.rename(columns = {'Modified_Image_Path':'Image_Path'}, inplace = True)\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Printing an Image"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:29.699126Z","iopub.status.busy":"2024-09-25T16:26:29.698665Z","iopub.status.idle":"2024-09-25T16:26:32.194451Z","shell.execute_reply":"2024-09-25T16:26:32.193090Z","shell.execute_reply.started":"2024-09-25T16:26:29.699067Z"},"trusted":true},"outputs":[],"source":["# Printing Input Directories\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    print(dirname)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:32.196721Z","iopub.status.busy":"2024-09-25T16:26:32.196227Z","iopub.status.idle":"2024-09-25T16:26:32.202784Z","shell.execute_reply":"2024-09-25T16:26:32.201521Z","shell.execute_reply.started":"2024-09-25T16:26:32.196677Z"},"trusted":true},"outputs":[],"source":["DIRECTORY = 'dataset' "]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:32.205051Z","iopub.status.busy":"2024-09-25T16:26:32.204636Z","iopub.status.idle":"2024-09-25T16:26:32.359254Z","shell.execute_reply":"2024-09-25T16:26:32.357476Z","shell.execute_reply.started":"2024-09-25T16:26:32.205007Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Displaying an Image\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","# Example image path\n","image_path = os.path.join(DIRECTORY, df['Image_Path'][0])\n","\n","# Open the image\n","image = Image.open(image_path)\n","\n","# Display the image using Matplotlib\n","plt.imshow(image)\n","plt.axis('off')  # Hide axis\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Splitting Dataset into test and Train"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:32.363243Z","iopub.status.busy":"2024-09-25T16:26:32.361970Z","iopub.status.idle":"2024-09-25T16:27:08.448518Z","shell.execute_reply":"2024-09-25T16:27:08.446260Z","shell.execute_reply.started":"2024-09-25T16:26:32.363170Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train_text shape: (3202, 1, 768)\n","X_train_images shape: (3202, 256, 256, 3)\n","y_train shape: (3202,)\n","X_test_text shape: (801, 1, 768)\n","X_test_images shape: (801, 256, 256, 3)\n","y_test shape: (801,)\n"]}],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","\n","# Load BERT embeddings and image paths\n","X_text_embeddings = np.array(df['BERT_Embeddings'].tolist())\n","image_paths = df['Image_Path'].tolist()\n","\n","# Load images\n","X_images = []\n","for path in image_paths:\n","    path = DIRECTORY + path\n","    image = Image.open(path)\n","    #onvert image to numpy array and normalize if needed\n","    image_array = np.array(image) / 255.0\n","    X_images.append(image_array)\n","\n","# Convert lists to numpy arrays\n","X_text_embeddings = np.array(X_text_embeddings)\n","X_images = np.array(X_images)\n","\n","# Reshape or normalize if required (already done in the provided code)\n","\n","# Prepare target data (labels)\n","y = np.arange(len(df))  # Assuming each row corresponds to a unique label\n","\n","# Split the data into training and testing sets\n","X_train_text, X_test_text, X_train_images, X_test_images, y_train, y_test = train_test_split(\n","    X_text_embeddings, X_images, y, test_size=0.2, random_state=42\n",")\n","\n","# Display shapes of the data\n","print(\"X_train_text shape:\", X_train_text.shape)\n","print(\"X_train_images shape:\", X_train_images.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"X_test_text shape:\", X_test_text.shape)\n","print(\"X_test_images shape:\", X_test_images.shape)\n","print(\"y_test shape:\", y_test.shape)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:08.454581Z","iopub.status.busy":"2024-09-25T16:27:08.453852Z","iopub.status.idle":"2024-09-25T16:27:08.463109Z","shell.execute_reply":"2024-09-25T16:27:08.461735Z","shell.execute_reply.started":"2024-09-25T16:27:08.454509Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reshaped X_train_text shape: (3202, 768)\n","Reshaped X_test_text shape: (801, 768)\n"]}],"source":["# Reshape the text embeddings to remove the extra dimension\n","X_train_text = X_train_text.reshape(X_train_text.shape[0], -1)\n","X_test_text = X_test_text.reshape(X_test_text.shape[0], -1)\n","\n","# Display shapes after reshaping\n","print(\"Reshaped X_train_text shape:\", X_train_text.shape)\n","print(\"Reshaped X_test_text shape:\", X_test_text.shape)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:08.465119Z","iopub.status.busy":"2024-09-25T16:27:08.464716Z","iopub.status.idle":"2024-09-25T16:27:08.480683Z","shell.execute_reply":"2024-09-25T16:27:08.478865Z","shell.execute_reply.started":"2024-09-25T16:27:08.465062Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train_text shape: (3202, 768)\n","X_train_images shape: (3202, 256, 256, 3)\n","X_test_text shape: (801, 768)\n","X_test_images shape: (801, 256, 256, 3)\n"]}],"source":["# Display shapes of the data\n","print(\"X_train_text shape:\", X_train_text.shape)\n","print(\"X_train_images shape:\", X_train_images.shape)\n","\n","print(\"X_test_text shape:\", X_test_text.shape)\n","print(\"X_test_images shape:\", X_test_images.shape)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:08.482290Z","iopub.status.busy":"2024-09-25T16:27:08.481902Z","iopub.status.idle":"2024-09-25T16:27:08.507689Z","shell.execute_reply":"2024-09-25T16:27:08.506392Z","shell.execute_reply.started":"2024-09-25T16:27:08.482258Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([-0.5754481 ,  0.0189473 ,  0.11817609,  0.02992155,  0.65141094,\n","       -0.20927459,  0.04845341,  0.5410135 ,  0.13207452, -0.63569915,\n","        0.207006  , -0.64307034, -0.38915625,  0.16688353, -0.30772436,\n","        0.46441597,  0.28175345,  0.20655034,  0.0714353 ,  0.34022012,\n","        0.05433815, -0.29941747, -0.17494744,  0.60304934,  0.12055178,\n","       -0.01095621, -0.02932324,  0.07023944, -0.19566831,  0.08874706,\n","        0.6439936 , -0.04744988, -0.00477395, -0.67380816,  0.15863612,\n","       -0.2338918 ,  0.19983698, -0.14235647, -0.5475427 ,  0.14933665,\n","       -0.7797225 , -0.18704425,  0.05365221,  0.08347022, -0.0300341 ,\n","       -0.18644734,  0.5152984 , -0.21001706, -0.21902874,  0.3655471 ,\n","       -0.48608094, -0.05752416, -0.14547814,  0.0989761 ,  0.33760992,\n","        0.8571075 , -0.378471  , -0.23348029, -0.4961075 , -0.46169376,\n","        0.4204655 , -0.18531236,  0.44366038, -0.50126475,  0.26569808,\n","       -0.03627625,  0.44500747,  0.5008911 , -0.41431153,  0.0714153 ,\n","       -0.35047236, -0.1730873 ,  0.27332258, -0.22023228,  0.06421003,\n","       -0.10399906, -0.03892432,  0.2957332 ,  0.19769955, -0.15385637,\n","       -0.29190457,  0.24236777, -0.32660013,  0.6214714 , -0.08492417,\n","       -0.21469826, -0.2980385 , -0.03923772, -0.7338831 ,  0.9133425 ,\n","       -0.16374484, -0.228833  ,  0.10093482,  0.05267303,  0.35804528,\n","        0.08741653,  0.25631386,  0.30761686,  0.03444256,  0.5968548 ,\n","        0.00578304, -0.07729679,  0.14876193,  0.0607245 ,  0.09437284,\n","       -0.43237275,  0.22763082, -0.23993339,  0.14797753,  0.36779073,\n","       -0.09939353, -0.3613384 ,  0.07963001, -0.21547528, -0.05586934,\n","        0.34242985,  0.20004375, -0.18293887,  0.14909098,  0.2665437 ,\n","        0.16316722,  0.0192323 , -0.0360994 ,  0.7035587 , -0.11102749,\n","        0.057201  , -0.24894293,  0.424746  , -0.2886099 , -0.30141714,\n","        0.12507857,  0.16251379,  0.34462082,  0.10543445, -0.10136723,\n","        0.39591953, -0.18888488, -0.10704794, -0.34078342,  0.48183125,\n","        0.25652066, -0.31015384,  0.35055947,  0.00829216, -0.01282884,\n","       -0.18792814, -0.25439608, -0.44483057, -0.09776392,  0.50225323,\n","        0.312329  ,  0.10934666,  0.25953197, -0.23863783, -0.09140077,\n","       -0.09288926, -0.19413343,  0.3549167 , -0.2596096 , -0.02861941,\n","        0.6388126 , -0.05447589, -0.17757696,  0.21514729, -0.10417841,\n","        0.30410987,  0.11357082,  0.5833514 , -0.43077257,  0.07600305,\n","       -0.33651778, -0.23797198,  0.8820481 , -0.09489372, -0.10669566,\n","       -0.13880251,  0.12255583,  0.2134936 ,  0.3765071 , -0.18764089,\n","       -0.5952923 ,  0.25893423, -0.24886543,  0.05211594,  0.6510507 ,\n","       -0.2961731 ,  0.5044235 , -0.357192  ,  0.00633896,  0.07436988,\n","        0.3427082 , -0.5423686 , -0.2867854 ,  0.02483355,  0.23905557,\n","       -0.3320396 , -0.23249745, -0.51313764, -0.5610836 ,  0.02270452,\n","        0.07921848, -0.06594992,  0.79860157,  0.26125544, -0.09365103,\n","       -0.4987985 , -0.05795961, -0.13297927,  0.2077885 ,  0.22564155,\n","       -0.06260696,  0.14493236,  0.09982064,  0.4570575 ,  0.16220497,\n","       -0.10625229,  0.175133  , -0.50295234,  0.44199672, -0.2559827 ,\n","        0.49437323,  0.10456964, -0.52650154,  0.63478553, -0.41534883,\n","        1.0645694 ,  0.11740503, -0.56049716,  0.0908746 ,  0.7129161 ,\n","       -0.13157383, -0.527778  ,  0.8022525 , -0.24632089, -0.30801755,\n","        0.26049098, -0.3362108 ,  0.2871287 ,  0.37712282, -0.40672636,\n","       -0.44092757,  0.49361646,  0.53776675, -0.13927118,  0.30915943,\n","        0.0087682 , -0.10088401, -0.18527056, -0.4062815 , -0.2610215 ,\n","       -0.4998008 , -0.20668755,  0.25629324, -0.68199736, -0.04970024,\n","       -0.4017093 ,  0.07906473, -0.22882038,  0.03992737, -0.08385258,\n","        0.17112567, -0.00455584,  0.2705676 ,  0.14184313, -0.37877846,\n","       -0.52480906,  0.228357  ,  0.8262507 , -0.09961925,  0.02217762,\n","        0.00860662, -0.08130046,  0.09301588,  0.6363797 , -0.45304602,\n","       -0.0238364 ,  0.36056682,  0.0592916 , -0.13429146, -0.5489628 ,\n","        0.30645838,  0.6704116 ,  0.12825035,  0.09252219,  0.12737769,\n","       -0.46711525,  0.28910694,  0.05636906, -0.33135918, -0.5218477 ,\n","       -0.01795679,  0.19199689, -0.1630251 , -0.42773396,  0.14213113,\n","       -0.15989837, -0.2874534 ,  0.06133073,  0.33316746, -0.14138444,\n","       -0.31976607, -0.21269123,  0.02955413,  0.03808765, -0.05902842,\n","       -0.0626005 , -0.08027871, -0.4580564 , -3.3100572 ,  0.31584838,\n","        0.06307743,  0.0591811 , -0.05391124, -0.28823304, -0.04926568,\n","       -0.03323754, -0.73939764,  0.09079885, -0.20429334, -0.30067104,\n","        0.63420755,  0.06416832,  0.43173966, -0.14856964, -0.47975716,\n","       -0.19743806, -0.0518141 ,  0.25625098, -0.3049817 , -0.42107168,\n","        0.20669341, -0.3556082 ,  0.7553556 ,  0.5475307 , -0.3838568 ,\n","       -0.2824743 , -0.33607468, -0.44259962,  0.15889074, -0.14398961,\n","       -0.00357509,  0.3337805 ,  0.36831212, -0.35687184,  0.07855239,\n","       -0.47017103, -0.24079196, -0.22119892,  0.25807756, -0.7542628 ,\n","       -0.04222978, -0.46317   ,  0.8865753 , -0.1938586 ,  0.20558605,\n","       -0.4555171 ,  0.1510828 ,  0.3626992 ,  0.38436124,  0.0448565 ,\n","       -0.09861397,  0.07297494, -0.2062308 , -0.11954276,  0.53088784,\n","        0.45732367, -0.20518456, -0.41735145, -0.10361478, -0.3014218 ,\n","       -0.5679759 , -0.18024196,  0.13040507, -0.6294914 , -0.35289747,\n","        0.4353009 ,  0.16946438,  0.38318646,  0.02536068,  0.5078607 ,\n","       -0.3669549 , -0.41965786, -0.21722758, -0.64630276,  0.17145137,\n","       -0.36464292, -0.05053375, -0.35406837,  0.1433597 , -0.5591974 ,\n","       -0.00611942,  0.035292  ,  0.11607687, -0.7107852 ,  0.23417181,\n","        0.11890043, -0.3108511 , -0.13401023,  0.0940587 ,  0.4325833 ,\n","       -0.17351831, -0.09384654,  0.23508716, -0.36447322,  0.35907218,\n","       -0.4000097 ,  0.25951424, -0.43179986,  0.06674982, -0.19591744,\n","        0.26710084, -0.04274069,  0.01433644, -0.21628375,  0.0246923 ,\n","        0.3466762 , -0.21677975, -0.05623873,  0.1726331 , -0.78465664,\n","        0.46547312, -0.26968226, -0.09451837, -0.26334497,  0.05385775,\n","        0.360864  , -0.36448348, -0.19562842,  0.05373451,  0.4388722 ,\n","       -0.2750612 , -0.22732306, -0.4399488 ,  0.24133566,  0.01216306,\n","       -0.33920246, -0.0836777 ,  0.25127804, -0.32185587, -0.14194334,\n","       -0.02678075,  0.34835204,  0.0470278 ,  0.2524112 , -0.20394126,\n","       -0.9437069 ,  0.1490453 ,  0.10604335,  0.11228458,  0.06708919,\n","       -0.09969863,  0.01090329, -0.35708576,  0.7570498 ,  0.25873902,\n","       -0.12201381, -0.19069283, -0.09525031, -0.4994209 , -0.2936042 ,\n","       -0.14331548, -0.20655648,  0.22837226,  0.18614855, -0.19811778,\n","        0.26111552, -0.2134996 , -0.5683189 ,  0.2140863 ,  0.01720108,\n","        0.49898186,  0.05033354, -0.38731897,  0.9805871 ,  0.00901103,\n","        0.33745778, -0.02557288,  0.32526526,  0.24776721, -0.5635481 ,\n","       -0.00744236, -0.2809889 , -0.20421298,  0.45483425, -0.16554044,\n","       -0.15523623, -0.05704835,  0.15390766, -0.12745461,  0.0730636 ,\n","       -0.15382247, -0.365741  ,  0.14953303, -0.03980146,  0.02564276,\n","       -0.45969567,  0.05728323,  0.25899744,  0.22006917,  0.11074182,\n","       -0.22594346,  0.06491846, -0.22608571, -0.55813426,  0.23932382,\n","        0.34912273, -0.02293242,  0.36318374,  0.27112707, -0.06324616,\n","       -0.44698644,  0.13549972,  0.21545137, -0.12955774,  0.4214165 ,\n","        0.3505492 ,  0.16976549,  0.3754776 , -0.56826293, -0.06183172,\n","       -0.5452734 , -0.12367322, -0.23171555, -0.477583  , -0.14452732,\n","       -0.12092187, -0.15712288, -0.16752239, -0.32302138, -0.11017393,\n","        0.18877631, -0.31559405, -0.65560085,  0.09663997,  0.32459775,\n","       -0.03093191, -0.1750226 , -0.5736046 ,  0.6593784 , -0.40957972,\n","        0.16900577, -0.00678745,  0.02114959,  0.09283423, -0.20349023,\n","       -0.92744297,  0.24543837,  0.289408  , -0.01611829, -0.17837858,\n","       -0.4534847 , -0.19522385,  0.2129491 , -0.02786582, -0.04448413,\n","        0.14492184, -0.00847939,  0.53806144, -0.13932036, -0.1048016 ,\n","        0.2730859 , -0.35071525,  0.10805654, -0.7805645 , -0.322231  ,\n","        0.09672112, -0.11379978, -0.02015167, -0.2592481 , -0.1806362 ,\n","       -0.10968934,  0.36508554,  0.2763766 ,  0.15791301, -0.10615356,\n","       -0.00900127, -0.13556975, -0.42808616,  0.36155853, -0.34430325,\n","        0.01082182, -0.38618368,  0.0131722 ,  0.38197628, -0.23198855,\n","       -0.45656937,  0.26088357, -0.55959177, -0.40975258, -0.10721393,\n","       -0.03349166, -0.04774118,  0.09792082, -0.09435553, -0.29775217,\n","        0.4820078 , -0.18036966, -0.22504319,  0.27546215, -0.07967655,\n","        0.1620081 ,  0.10541795,  0.02982367,  0.23623957,  0.5733647 ,\n","        0.25618628,  0.04920441, -0.17383501,  0.0244759 , -0.0922219 ,\n","       -0.40381223,  0.27199945, -0.13184987,  0.24759655,  0.09231931,\n","       -0.54188436, -0.04435676,  0.29133722, -0.18525267, -0.45178273,\n","        0.67244494,  0.39480105, -0.7640701 , -0.15973412, -0.26980117,\n","       -0.04738321,  0.10639863, -0.19836739,  0.21385029, -0.09024748,\n","        0.8583223 ,  0.3004621 ,  0.13861758,  0.59524846, -0.2974639 ,\n","        0.02505656, -0.25067103,  0.19936238, -0.09546243,  0.24764925,\n","       -0.3246696 ,  0.38646147, -0.02610948, -0.04818762, -0.5730099 ,\n","        0.05359725,  0.2663716 , -0.3651441 , -0.26788965,  0.18384476,\n","        0.29429373,  0.5645809 ,  0.6358598 ,  0.27478543,  0.25341642,\n","       -0.44970647,  0.8695551 ,  0.16464233,  0.12956004,  0.10247046,\n","        0.14114727, -0.35181305, -0.08469529,  0.72639686,  0.45296422,\n","        0.15686154, -0.05036012,  1.044883  ,  0.52272844,  0.24295035,\n","        0.58987004, -0.52488935, -0.290401  ,  0.10190949,  0.25984767,\n","       -0.61943376, -0.29755563,  0.28262126,  0.01946517,  0.31395847,\n","        0.2248702 , -0.35801992, -0.05760279,  1.2359482 , -0.05548104,\n","        0.06078491, -0.16257118,  0.02677738,  0.40401083,  0.13122945,\n","       -0.56819594, -0.7264039 ,  0.08814319, -0.37416187,  0.24884188,\n","        0.2590642 ,  0.02926009, -0.28651896,  0.08618268, -0.17162366,\n","        0.47692674, -0.60009587, -0.10091455, -0.61379206,  0.438452  ,\n","       -0.01318318,  0.8650698 , -0.06298966,  0.29127526, -0.1730495 ,\n","       -0.09404317, -0.1505509 , -0.03297953,  0.07335895, -0.10079341,\n","        0.14204668, -0.03638513,  0.02698858,  0.09550305,  0.4353172 ,\n","       -0.1689573 , -0.01921727,  0.23209265, -0.21497707,  0.17402475,\n","       -0.14347443, -0.40463868,  0.18255413, -0.22065195, -0.36481768,\n","       -0.09638709,  0.03101354, -0.36168444, -0.48371628,  0.22167055,\n","       -0.01860575,  0.17741694, -0.17981331, -0.38673818,  0.31815076,\n","       -0.11089641,  0.49114877, -0.48888546, -0.39990515, -0.04676212,\n","        0.14191984, -0.18312635, -0.2846807 ,  0.47055677,  0.45524302,\n","       -0.05592088,  0.22505474,  0.4283567 , -0.227645  , -0.32102665,\n","       -0.5122114 ,  0.20375803, -0.35879934,  0.05686883, -0.2556379 ,\n","        0.16593324, -0.51783425, -0.49138048, -0.06027102, -0.16635352,\n","        0.22152266,  0.4652689 ,  0.08877223], dtype=float32)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# VERIFICATION\n","X_train_text[0]"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:08.509711Z","iopub.status.busy":"2024-09-25T16:27:08.509317Z","iopub.status.idle":"2024-09-25T16:27:08.781656Z","shell.execute_reply":"2024-09-25T16:27:08.780460Z","shell.execute_reply.started":"2024-09-25T16:27:08.509665Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# displaying images\n","data = X_train_images[2]\n","from matplotlib import pyplot as plt\n","plt.imshow(data, interpolation='nearest')\n","plt.show()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:08.783595Z","iopub.status.busy":"2024-09-25T16:27:08.783233Z","iopub.status.idle":"2024-09-25T16:27:09.464508Z","shell.execute_reply":"2024-09-25T16:27:09.462937Z","shell.execute_reply.started":"2024-09-25T16:27:08.783564Z"},"trusted":true},"outputs":[],"source":["# DO NOT RUN THIS , skip to next cell.\n","import cv2\n","resized_images = []\n","\n","# Define the new dimensions\n","new_width = 64\n","new_height = 64\n","\n","for image in X_train_images:\n","    resized_img = cv2.resize(image, (new_width, new_height))  \n","    resized_images.append(resized_img)\n","\n","# Now, resized_images will contain your resized images ready for passing into GAN\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:09.467101Z","iopub.status.busy":"2024-09-25T16:27:09.466608Z","iopub.status.idle":"2024-09-25T16:27:09.475698Z","shell.execute_reply":"2024-09-25T16:27:09.474120Z","shell.execute_reply.started":"2024-09-25T16:27:09.467038Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(3202, 256, 256, 3)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["X_train_images.shape"]},{"cell_type":"markdown","metadata":{},"source":["# Applying CGANs"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:09.477974Z","iopub.status.busy":"2024-09-25T16:27:09.477544Z","iopub.status.idle":"2024-09-25T16:27:19.185105Z","shell.execute_reply":"2024-09-25T16:27:19.184116Z","shell.execute_reply.started":"2024-09-25T16:27:09.477939Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-09-25 16:27:11.616074: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-25 16:27:11.616256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-25 16:27:11.762532: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import skimage as ski\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:19.188115Z","iopub.status.busy":"2024-09-25T16:27:19.186860Z","iopub.status.idle":"2024-09-25T16:27:19.204400Z","shell.execute_reply":"2024-09-25T16:27:19.203314Z","shell.execute_reply.started":"2024-09-25T16:27:19.188043Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, Model\n","\n","# Define Generator\n","def build_generator():\n","    input_text = layers.Input(shape=(768,))\n","    x = layers.Dense(256, activation='relu')(input_text)\n","    x = layers.Dense(256, activation='relu')(x)\n","    x = layers.Reshape((16, 16, 1))(x)\n","    \n","    input_noise = layers.Input(shape=(100,))\n","    y = layers.Dense(256 * 16 * 16, activation='relu')(input_noise)\n","    y = layers.Reshape((16, 16, 256))(y)\n","    \n","    concatenated = layers.Concatenate(axis=-1)([x, y])\n","    \n","    # Conv2DTranspose layers to progressively upsample to 256x256\n","    x = layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', activation='relu')(concatenated)  # 16x16 -> 32x32\n","    x = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)              # 32x32 -> 64x64\n","    x = layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)              # 64x64 -> 128x128\n","    output = layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', activation='sigmoid')(x)        # 128x128 -> 256x256\n","    \n","    model = Model(inputs=[input_text, input_noise], outputs=output)\n","    return model\n","\n","# Define Discriminator\n","def build_discriminator():\n","    input_image = layers.Input(shape=(256, 256, 3))\n","    x = layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', activation='relu')(input_image)\n","    x = layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)\n","    x = layers.Flatten()(x)\n","    x = layers.Dense(1, activation='sigmoid')(x)\n","    \n","    model = Model(inputs=input_image, outputs=x)\n","    return model"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:19.206370Z","iopub.status.busy":"2024-09-25T16:27:19.205866Z","iopub.status.idle":"2024-09-25T16:27:19.435649Z","shell.execute_reply":"2024-09-25T16:27:19.434541Z","shell.execute_reply.started":"2024-09-25T16:27:19.206329Z"},"trusted":true},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65536</span>)     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,619,136</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span>)              │            │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_transpose    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">822,528</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_transpose_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">204,864</span> │ conv2d_transpose… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_transpose_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">51,232</span> │ conv2d_transpose… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_transpose_3  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,403</span> │ conv2d_transpose… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m196,864\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65536\u001b[0m)     │  \u001b[38;5;34m6,619,136\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n","│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m257\u001b[0m)              │            │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_transpose    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m822,528\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n","│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_transpose_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m204,864\u001b[0m │ conv2d_transpose… │\n","│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_transpose_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │     \u001b[38;5;34m51,232\u001b[0m │ conv2d_transpose… │\n","│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_transpose_3  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │      \u001b[38;5;34m2,403\u001b[0m │ conv2d_transpose… │\n","│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,962,819</span> (30.38 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,962,819\u001b[0m (30.38 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,962,819</span> (30.38 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,962,819\u001b[0m (30.38 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["generator = build_generator()\n","generator.summary()"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:19.438280Z","iopub.status.busy":"2024-09-25T16:27:19.437285Z","iopub.status.idle":"2024-09-25T16:27:19.453427Z","shell.execute_reply":"2024-09-25T16:27:19.452254Z","shell.execute_reply.started":"2024-09-25T16:27:19.438237Z"},"trusted":true},"outputs":[],"source":["class CGAN(Model):\n","    def __init__(self, generator, discriminator):\n","        super(CGAN, self).__init__()\n","        self.generator = generator\n","        self.discriminator = discriminator\n","\n","    def compile(self, g_optimizer, d_optimizer, loss_fn):\n","        super(CGAN, self).compile()\n","        self.g_optimizer = g_optimizer\n","        self.d_optimizer = d_optimizer\n","        self.loss_fn = loss_fn\n","\n","    def call(self, inputs):\n","        text, noise = inputs\n","        generated_images = self.generator([text, noise])\n","        return self.discriminator(generated_images)\n","\n","    def train_step(self, data):\n","        text_embeddings, real_images = data[0]\n","        batch_size = tf.shape(real_images)[0]\n","        print(batch_size)\n","        noise = tf.random.normal((batch_size, 100))\n","\n","        # Train discriminator\n","        with tf.GradientTape() as tape:\n","            generated_images = self.generator([text_embeddings, noise], training=True)\n","            real_output = self.discriminator(real_images, training=True)\n","            fake_output = self.discriminator(generated_images, training=True)\n","            d_loss_real = self.loss_fn(tf.ones_like(real_output), real_output)\n","            d_loss_fake = self.loss_fn(tf.zeros_like(fake_output), fake_output)\n","            d_loss = d_loss_real + d_loss_fake\n","\n","        d_gradients = tape.gradient(d_loss, self.discriminator.trainable_variables)\n","        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n","\n","        # Train generator\n","        with tf.GradientTape() as tape:\n","            generated_images = self.generator([text_embeddings, noise], training=True)\n","            fake_output = self.discriminator(generated_images, training=True)\n","            g_loss = self.loss_fn(tf.ones_like(fake_output), fake_output)\n","\n","        g_gradients = tape.gradient(g_loss, self.generator.trainable_variables)\n","        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n","\n","        return {'d_loss': d_loss, 'g_loss': g_loss}\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:19.455266Z","iopub.status.busy":"2024-09-25T16:27:19.454866Z","iopub.status.idle":"2024-09-25T16:27:19.470793Z","shell.execute_reply":"2024-09-25T16:27:19.469377Z","shell.execute_reply.started":"2024-09-25T16:27:19.455235Z"},"trusted":true},"outputs":[],"source":["real_images = X_train_images[:100]\n","text_embeddings = X_train_text[:100]"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:19.472515Z","iopub.status.busy":"2024-09-25T16:27:19.472171Z","iopub.status.idle":"2024-09-25T16:27:19.488519Z","shell.execute_reply":"2024-09-25T16:27:19.487450Z","shell.execute_reply.started":"2024-09-25T16:27:19.472488Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(100, 256, 256, 3)\n","(100, 768)\n"]}],"source":["print(real_images.shape)\n","print(text_embeddings.shape)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:19.490823Z","iopub.status.busy":"2024-09-25T16:27:19.490367Z","iopub.status.idle":"2024-09-25T16:27:19.503173Z","shell.execute_reply":"2024-09-25T16:27:19.501976Z","shell.execute_reply.started":"2024-09-25T16:27:19.490783Z"},"trusted":true},"outputs":[{"data":{"text/plain":["numpy.ndarray"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["type(real_images)\n","type(text_embeddings)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:19.504777Z","iopub.status.busy":"2024-09-25T16:27:19.504433Z","iopub.status.idle":"2024-09-25T16:35:23.815103Z","shell.execute_reply":"2024-09-25T16:35:23.813349Z","shell.execute_reply.started":"2024-09-25T16:27:19.504748Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py:695: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n","  output, from_logits = _get_logits(\n"]},{"name":"stdout","output_type":"stream","text":["Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5s/step - d_loss: 2.0853 - g_loss: 0.5442 - loss: 0.0000e+00\n","Epoch 2/15\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 1.1339 - g_loss: 0.5920 - loss: 0.0000e+00\n","Epoch 3/15\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5s/step - d_loss: 0.6783 - g_loss: 1.3047 - loss: 0.0000e+00\n","Epoch 4/15\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 0.2881 - g_loss: 2.2170 - loss: 0.0000e+00\n","Epoch 5/15\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5s/step - d_loss: 0.2265 - g_loss: 3.3556 - loss: 0.0000e+00\n","Epoch 6/15\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 0.9529 - g_loss: 2.2844 - loss: 0.0000e+00\n","Epoch 7/15\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 0.1851 - g_loss: 3.7187 - loss: 0.0000e+00\n","Epoch 8/15\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 6s/step - d_loss: 0.0611 - g_loss: 3.7983 - loss: 0.0000e+00\n","Epoch 9/15\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 0.1723 - g_loss: 2.9091 - loss: 0.0000e+00\n","Epoch 10/15\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5s/step - d_loss: 0.1209 - g_loss: 3.9403 - loss: 0.0000e+00\n","Epoch 11/15\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 1.0487 - g_loss: 2.5071 - loss: 0.0000e+00\n","Epoch 12/15\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 0.4697 - g_loss: 5.0765 - loss: 0.0000e+00\n","Epoch 13/15\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 1.8181 - g_loss: 2.3165 - loss: 0.0000e+00\n","Epoch 14/15\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5s/step - d_loss: 0.0437 - g_loss: 4.6444 - loss: 0.0000e+00\n","Epoch 15/15\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5s/step - d_loss: 0.0651 - g_loss: 3.3345 - loss: 0.0000e+00\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x792ef6909e40>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Build and compile models\n","generator = build_generator()\n","discriminator = build_discriminator()\n","cgan = CGAN(generator, discriminator)\n","cgan.compile(\n","    g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n","    d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n","    loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",")\n","\n","# Assuming text_embeddings and real_images are NumPy arrays\n","data = (text_embeddings, real_images)\n","# print(\"This is from here\")\n","# print(data)\n","# Train CGAN\n","cgan.fit(data, epochs=15, batch_size=32)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Codium Code"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:51:48.551425Z","iopub.status.busy":"2024-09-25T16:51:48.550793Z","iopub.status.idle":"2024-09-25T16:51:48.572954Z","shell.execute_reply":"2024-09-25T16:51:48.571369Z","shell.execute_reply.started":"2024-09-25T16:51:48.551380Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","\n","# Generator model\n","class Generator(nn.Module):\n","    def __init__(self, embedding_dim, image_channels=3):\n","        super(Generator, self).__init__()\n","        \n","        self.embedding_dim = embedding_dim\n","        \n","        self.fc = nn.Linear(embedding_dim, 256*256*3)\n","        self.conv_blocks = nn.Sequential(\n","            nn.Conv2d(image_channels + 100, 64, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, image_channels, kernel_size=3, stride=1, padding=1),\n","            nn.Tanh()\n","        )\n","    \n","    def forward(self, noise, text_embeddings):\n","        x = self.fc(text_embeddings)\n","        x = x.view(x.size(0), 3, 256, 256)  # Reshape the output to match the size of the image\n","        noise = noise.view(noise.size(0), 100, 1, 1)  # Expand noise to match the spatial dimensions of x\n","        noise = noise.repeat(1, 1, 256, 256)  # Repeat noise to match the spatial dimensions of x\n","        x = torch.cat([x, noise], dim=1)  # Concatenate noise with the image along the channel dimension\n","        x = self.conv_blocks(x)\n","        return x\n","\n","# Discriminator model\n","class Discriminator(nn.Module):\n","    def __init__(self, image_channels=3, embedding_dim=768):\n","        super(Discriminator, self).__init__()\n","\n","        # Project the text embeddings to match the image channels (3 channels)\n","        self.embedding_conv = nn.Conv2d(embedding_dim, image_channels, kernel_size=1)\n","\n","        self.conv_blocks = nn.Sequential(\n","            nn.Conv2d(image_channels * 2, 64, kernel_size=3, stride=2, padding=1),  # Image + Embedding channels\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # Add more Conv2d layers as needed\n","        )\n","        \n","        self.fc = nn.Linear(64 * 128 * 128, 1)\n","    \n","    def forward(self, images, text_embeddings):\n","        # Corrected: Assuming images are in shape (batch_size, height, width, channels), permute them properly.\n","        images = images.permute(0, 3, 1, 2)  # Correct permutation: (batch_size, channels, height, width)\n","        \n","        # Project text embeddings to image dimensions\n","        text_embeddings = text_embeddings.view(text_embeddings.size(0), text_embeddings.size(1), 1, 1)\n","        text_embeddings = text_embeddings.repeat(1, 1, 256, 256)  # Shape: (batch_size, 768, 256, 256)\n","        \n","        # Apply the 1x1 convolution to reduce the channels of text embeddings\n","        projected_embeddings = self.embedding_conv(text_embeddings)  # Shape: (batch_size, 3, 256, 256)\n","        \n","        # Ensure both images and projected embeddings have the same shape\n","        if images.shape != projected_embeddings.shape:\n","            raise RuntimeError(f\"Shape mismatch: images {images.shape}, embeddings {projected_embeddings.shape}\")\n","        \n","        # Concatenate images and projected embeddings along the channel dimension\n","        x = torch.cat([images, projected_embeddings], dim=1)  # Shape: (batch_size, 6, 256, 256)\n","        \n","        # Pass through the convolutional layers\n","        x = self.conv_blocks(x)\n","        x = x.view(x.size(0), -1)  # Flatten for fully connected layer\n","        \n","        # Compute validity\n","        validity = self.fc(x)\n","        return validity"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:51:51.860117Z","iopub.status.busy":"2024-09-25T16:51:51.859163Z","iopub.status.idle":"2024-09-25T16:51:52.543680Z","shell.execute_reply":"2024-09-25T16:51:52.542472Z","shell.execute_reply.started":"2024-09-25T16:51:51.860041Z"},"trusted":true},"outputs":[],"source":["# Custom Dataset\n","class CustomDataset(Dataset):\n","    def __init__(self, real_images, text_embeddings):\n","        self.real_images = real_images\n","        self.text_embeddings = text_embeddings\n","    \n","    def __len__(self):\n","        return len(self.real_images)\n","    \n","    def __getitem__(self, idx):\n","        image = torch.tensor(self.real_images[idx], dtype=torch.float32)\n","        embedding = torch.tensor(self.text_embeddings[idx], dtype=torch.float32)\n","        return image, embedding\n","\n","# Placeholder for actual data (replace with your real data)\n","real_images = np.random.randn(100, 256, 256, 3).astype(np.float32)  # 100 RGB images\n","text_embeddings = np.random.randn(100, 768).astype(np.float32)  # 100 text embeddings\n","\n","# Create an instance of the CustomDataset\n","custom_dataset = CustomDataset(real_images, text_embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:51:55.601449Z","iopub.status.busy":"2024-09-25T16:51:55.600114Z"},"trusted":true},"outputs":[],"source":["# Create a PyTorch DataLoader to iterate over the dataset\n","batch_size = 16\n","data_loader = DataLoader(dataset=custom_dataset, batch_size=batch_size, shuffle=True)\n","\n","# Instantiate the Generator and Discriminator models\n","generator = Generator(embedding_dim=768)\n","discriminator = Discriminator()\n","\n","# Define optimizers for Generator and Discriminator\n","optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","\n","# Training loop\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    for i, (images, text_embeddings) in enumerate(data_loader):\n","        # Train the Discriminator\n","        optimizer_D.zero_grad()\n","        \n","        # Generate fake images from Generator\n","        noise = torch.randn(batch_size, 100)\n","        fake_images = generator(noise, text_embeddings)\n","        \n","        # Compute Discriminator loss\n","        real_loss = discriminator(images, text_embeddings)\n","        fake_loss = discriminator(fake_images, text_embeddings)\n","        d_loss = -torch.mean(real_loss) + torch.mean(fake_loss)\n","        \n","        d_loss.backward()\n","        optimizer_D.step()\n","        \n","        # Train the Generator\n","        optimizer_G.zero_grad()\n","        \n","        # Generate fake images from Generator\n","        noise = torch.randn(batch_size, 100)\n","        fake_images = generator(noise, text_embeddings)\n","        \n","        # Compute Generator loss\n","        g_loss = -torch.mean(discriminator(fake_images, text_embeddings))\n","        \n","        g_loss.backward()\n","        optimizer_G.step()"]},{"cell_type":"markdown","metadata":{},"source":["# ATTEMPT 3"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:52:08.446994Z","iopub.status.busy":"2024-09-25T16:52:08.445930Z","iopub.status.idle":"2024-09-25T16:52:08.864704Z","shell.execute_reply":"2024-09-25T16:52:08.863153Z","shell.execute_reply.started":"2024-09-25T16:52:08.446949Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'X_train_images' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m real_images \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_images\u001b[49m[:\u001b[38;5;241m100\u001b[39m]\n\u001b[1;32m      2\u001b[0m text_embeddings \u001b[38;5;241m=\u001b[39m X_train_text[:\u001b[38;5;241m100\u001b[39m]\n","\u001b[0;31mNameError\u001b[0m: name 'X_train_images' is not defined"]}],"source":["real_images = X_train_images[:100]\n","text_embeddings = X_train_text[:100]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-25T16:35:44.924959Z","iopub.status.idle":"2024-09-25T16:35:44.925469Z","shell.execute_reply":"2024-09-25T16:35:44.925258Z","shell.execute_reply.started":"2024-09-25T16:35:44.925239Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","# Define the target image resolution\n","TARGET_HEIGHT, TARGET_WIDTH = 128, 128\n","\n","# Function to resize images\n","def resize_images(images):\n","    resized_images = []\n","    for image in images:\n","        resized_image = cv2.resize(image, (TARGET_WIDTH, TARGET_HEIGHT))\n","        resized_images.append(resized_image)\n","    return np.array(resized_images)\n","\n","# Example usage:\n","real_images = resize_images(real_images)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-25T16:35:44.926928Z","iopub.status.idle":"2024-09-25T16:35:44.927417Z","shell.execute_reply":"2024-09-25T16:35:44.927210Z","shell.execute_reply.started":"2024-09-25T16:35:44.927191Z"},"trusted":true},"outputs":[],"source":["real_images.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-25T16:35:44.929637Z","iopub.status.idle":"2024-09-25T16:35:44.930274Z","shell.execute_reply":"2024-09-25T16:35:44.929906Z","shell.execute_reply.started":"2024-09-25T16:35:44.929887Z"},"trusted":true},"outputs":[],"source":["# Modify the build_generator function to accept resized images\n","def build_generator():\n","    text_embedding_input = Input(shape=(TEXT_EMBEDDING_DIM,))\n","    latent_input = Input(shape=(LATENT_DIM,))\n","    \n","    # Concatenate text embedding and latent noise vector\n","    merged_input = Concatenate()([text_embedding_input, latent_input])\n","    \n","    # Fully connected layer to map to initial shape\n","    x = Dense(32 * 32 * 128, activation='relu')(merged_input)  # Adjust based on the size of your resized images\n","    x = Reshape((32, 32, 128))(x)  # Adjust based on the size of your resized images\n","    \n","    # Convolutional layers to upsample the image\n","    x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)\n","    x = Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)\n","    generated_image = Conv2DTranspose(IMAGE_CHANNELS, (5, 5), strides=(2, 2), padding='same', activation='tanh')(x)\n","\n","    model = Model(inputs=[text_embedding_input, latent_input], outputs=generated_image)\n","    return model\n","\n","# Modify the build_discriminator function to accept resized images\n","def build_discriminator():\n","    image_input = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))  # Adjust based on the size of your resized images\n","    text_embedding_input = Input(shape=(TEXT_EMBEDDING_DIM,))\n","    \n","    # Embedding layer to map text embedding to the same space as image\n","    embedded_text = Dense(IMAGE_HEIGHT * IMAGE_WIDTH * IMAGE_CHANNELS, activation='relu')(text_embedding_input)  # Adjust based on the size of your resized images\n","    embedded_text = Reshape((IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))(embedded_text)  # Adjust based on the size of your resized images\n","    \n","    # Resize the embedded text to match the spatial dimensions of the image\n","    embedded_text = tf.image.resize(embedded_text, (IMAGE_HEIGHT, IMAGE_WIDTH), method='nearest')\n","    \n","    # Concatenate image and text embedding\n","    merged_input = Concatenate()([image_input, embedded_text])\n","    \n","    # Convolutional layers to downsample the image\n","    x = Conv2D(32, (5, 5), strides=(2, 2), padding='same', activation='relu')(merged_input)\n","    x = Conv2D(64, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)\n","    x = Conv2D(128, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)\n","    flattened = Flatten()(x)\n","    \n","    # Fully connected layer for binary classification\n","    discriminator_output = Dense(1, activation='sigmoid')(flattened)\n","\n","    model = Model(inputs=[image_input, text_embedding_input], outputs=discriminator_output)\n","    return model\n","\n","# Create placeholders for text embeddings and latent vectors\n","text_embedding_input = Input(shape=(TEXT_EMBEDDING_DIM,))\n","latent_input = Input(shape=(LATENT_DIM,))\n","\n","# Build and compile the models\n","generator = build_generator()\n","discriminator = build_discriminator()\n","\n","generator_optimizer = Adam(lr=0.0002, beta_1=0.5)\n","discriminator_optimizer = Adam(lr=0.0002, beta_1=0.5)\n","\n","generator.compile(loss='binary_crossentropy', optimizer=generator_optimizer)\n","discriminator.compile(loss='binary_crossentropy', optimizer=discriminator_optimizer)\n","\n","# Combined model (Generator + Discriminator)\n","discriminator.trainable = False\n","generated_image = generator([text_embedding_input, latent_input])\n","validity = discriminator([generated_image, text_embedding_input])\n","combined = Model(inputs=[text_embedding_input, latent_input], outputs=validity)\n","combined.compile(loss='binary_crossentropy', optimizer=generator_optimizer)\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4855355,"sourceId":8196933,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
