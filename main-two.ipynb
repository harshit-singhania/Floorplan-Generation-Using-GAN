{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-25T16:26:28.106119Z","iopub.status.busy":"2024-09-25T16:26:28.105563Z","iopub.status.idle":"2024-09-25T16:26:29.383573Z","shell.execute_reply":"2024-09-25T16:26:29.382331Z","shell.execute_reply.started":"2024-09-25T16:26:28.106047Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:29.386064Z","iopub.status.busy":"2024-09-25T16:26:29.385573Z","iopub.status.idle":"2024-09-25T16:26:29.604512Z","shell.execute_reply":"2024-09-25T16:26:29.603262Z","shell.execute_reply.started":"2024-09-25T16:26:29.386031Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>File_Name</th>\n","      <th>Text</th>\n","      <th>Image_Path</th>\n","      <th>BERT_Embeddings</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10017</td>\n","      <td>The balcony juts out on the south side, with t...</td>\n","      <td>../floorplan_image\\10017.png</td>\n","      <td>[[-0.6216691, -0.029034398, 0.045137372, -0.09...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10042</td>\n","      <td>The balcony is in the southeastern corner of t...</td>\n","      <td>../floorplan_image\\10042.png</td>\n","      <td>[[-0.6944888, 0.015425202, -0.0041255075, -0.1...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10045</td>\n","      <td>bathroom is in north side of the house, next t...</td>\n","      <td>../floorplan_image\\10045.png</td>\n","      <td>[[-0.6030773, -0.0011889015, 0.045667697, -0.1...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10047</td>\n","      <td>The balcony is in the north east corner, just ...</td>\n","      <td>../floorplan_image\\10047.png</td>\n","      <td>[[-0.69215715, -0.052971497, 0.03891414, -0.02...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10052</td>\n","      <td>The balcony is on the southwest side of the ap...</td>\n","      <td>../floorplan_image\\10052.png</td>\n","      <td>[[-0.61126614, -0.005761562, -0.054692637, 0.0...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  File_Name                                               Text  \\\n","0     10017  The balcony juts out on the south side, with t...   \n","1     10042  The balcony is in the southeastern corner of t...   \n","2     10045  bathroom is in north side of the house, next t...   \n","3     10047  The balcony is in the north east corner, just ...   \n","4     10052  The balcony is on the southwest side of the ap...   \n","\n","                     Image_Path  \\\n","0  ../floorplan_image\\10017.png   \n","1  ../floorplan_image\\10042.png   \n","2  ../floorplan_image\\10045.png   \n","3  ../floorplan_image\\10047.png   \n","4  ../floorplan_image\\10052.png   \n","\n","                                     BERT_Embeddings  \n","0  [[-0.6216691, -0.029034398, 0.045137372, -0.09...  \n","1  [[-0.6944888, 0.015425202, -0.0041255075, -0.1...  \n","2  [[-0.6030773, -0.0011889015, 0.045667697, -0.1...  \n","3  [[-0.69215715, -0.052971497, 0.03891414, -0.02...  \n","4  [[-0.61126614, -0.005761562, -0.054692637, 0.0...  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["dataset_path = os.path.join('dataset', 'word_embeddings_dataframe.pkl')\n","df = pd.read_pickle(dataset_path) \n","df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:29.606581Z","iopub.status.busy":"2024-09-25T16:26:29.606196Z","iopub.status.idle":"2024-09-25T16:26:29.651398Z","shell.execute_reply":"2024-09-25T16:26:29.650134Z","shell.execute_reply.started":"2024-09-25T16:26:29.606550Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>File_Name</th>\n","      <th>Text</th>\n","      <th>Image_Path</th>\n","      <th>BERT_Embeddings</th>\n","      <th>Modified_Image_Path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10017</td>\n","      <td>The balcony juts out on the south side, with t...</td>\n","      <td>../floorplan_image\\10017.png</td>\n","      <td>[[-0.6216691, -0.029034398, 0.045137372, -0.09...</td>\n","      <td>human_annotated_images/10017.png</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10042</td>\n","      <td>The balcony is in the southeastern corner of t...</td>\n","      <td>../floorplan_image\\10042.png</td>\n","      <td>[[-0.6944888, 0.015425202, -0.0041255075, -0.1...</td>\n","      <td>human_annotated_images/10042.png</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10045</td>\n","      <td>bathroom is in north side of the house, next t...</td>\n","      <td>../floorplan_image\\10045.png</td>\n","      <td>[[-0.6030773, -0.0011889015, 0.045667697, -0.1...</td>\n","      <td>human_annotated_images/10045.png</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10047</td>\n","      <td>The balcony is in the north east corner, just ...</td>\n","      <td>../floorplan_image\\10047.png</td>\n","      <td>[[-0.69215715, -0.052971497, 0.03891414, -0.02...</td>\n","      <td>human_annotated_images/10047.png</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10052</td>\n","      <td>The balcony is on the southwest side of the ap...</td>\n","      <td>../floorplan_image\\10052.png</td>\n","      <td>[[-0.61126614, -0.005761562, -0.054692637, 0.0...</td>\n","      <td>human_annotated_images/10052.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  File_Name                                               Text  \\\n","0     10017  The balcony juts out on the south side, with t...   \n","1     10042  The balcony is in the southeastern corner of t...   \n","2     10045  bathroom is in north side of the house, next t...   \n","3     10047  The balcony is in the north east corner, just ...   \n","4     10052  The balcony is on the southwest side of the ap...   \n","\n","                     Image_Path  \\\n","0  ../floorplan_image\\10017.png   \n","1  ../floorplan_image\\10042.png   \n","2  ../floorplan_image\\10045.png   \n","3  ../floorplan_image\\10047.png   \n","4  ../floorplan_image\\10052.png   \n","\n","                                     BERT_Embeddings  \\\n","0  [[-0.6216691, -0.029034398, 0.045137372, -0.09...   \n","1  [[-0.6944888, 0.015425202, -0.0041255075, -0.1...   \n","2  [[-0.6030773, -0.0011889015, 0.045667697, -0.1...   \n","3  [[-0.69215715, -0.052971497, 0.03891414, -0.02...   \n","4  [[-0.61126614, -0.005761562, -0.054692637, 0.0...   \n","\n","                Modified_Image_Path  \n","0  human_annotated_images/10017.png  \n","1  human_annotated_images/10042.png  \n","2  human_annotated_images/10045.png  \n","3  human_annotated_images/10047.png  \n","4  human_annotated_images/10052.png  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Function to modify image path\n","def modify_image_path(image_path):\n","    filename = os.path.basename(image_path).split(\"floorplan_image\\\\\")[1]\n","    new_path = os.path.join(\"human_annotated_images\", filename)\n","    return new_path\n","\n","# Apply the function to the 'Image_Path' column in the DataFrame\n","df['Modified_Image_Path'] = df['Image_Path'].apply(modify_image_path)\n","\n","df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:29.654677Z","iopub.status.busy":"2024-09-25T16:26:29.653797Z","iopub.status.idle":"2024-09-25T16:26:29.668351Z","shell.execute_reply":"2024-09-25T16:26:29.667029Z","shell.execute_reply.started":"2024-09-25T16:26:29.654639Z"},"trusted":true},"outputs":[],"source":["df.drop(['Image_Path'], axis = 1, inplace = True)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:29.670430Z","iopub.status.busy":"2024-09-25T16:26:29.669913Z","iopub.status.idle":"2024-09-25T16:26:29.696949Z","shell.execute_reply":"2024-09-25T16:26:29.695844Z","shell.execute_reply.started":"2024-09-25T16:26:29.670384Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>File_Name</th>\n","      <th>Text</th>\n","      <th>BERT_Embeddings</th>\n","      <th>Image_Path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10017</td>\n","      <td>The balcony juts out on the south side, with t...</td>\n","      <td>[[-0.6216691, -0.029034398, 0.045137372, -0.09...</td>\n","      <td>human_annotated_images/10017.png</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10042</td>\n","      <td>The balcony is in the southeastern corner of t...</td>\n","      <td>[[-0.6944888, 0.015425202, -0.0041255075, -0.1...</td>\n","      <td>human_annotated_images/10042.png</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10045</td>\n","      <td>bathroom is in north side of the house, next t...</td>\n","      <td>[[-0.6030773, -0.0011889015, 0.045667697, -0.1...</td>\n","      <td>human_annotated_images/10045.png</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10047</td>\n","      <td>The balcony is in the north east corner, just ...</td>\n","      <td>[[-0.69215715, -0.052971497, 0.03891414, -0.02...</td>\n","      <td>human_annotated_images/10047.png</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10052</td>\n","      <td>The balcony is on the southwest side of the ap...</td>\n","      <td>[[-0.61126614, -0.005761562, -0.054692637, 0.0...</td>\n","      <td>human_annotated_images/10052.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  File_Name                                               Text  \\\n","0     10017  The balcony juts out on the south side, with t...   \n","1     10042  The balcony is in the southeastern corner of t...   \n","2     10045  bathroom is in north side of the house, next t...   \n","3     10047  The balcony is in the north east corner, just ...   \n","4     10052  The balcony is on the southwest side of the ap...   \n","\n","                                     BERT_Embeddings  \\\n","0  [[-0.6216691, -0.029034398, 0.045137372, -0.09...   \n","1  [[-0.6944888, 0.015425202, -0.0041255075, -0.1...   \n","2  [[-0.6030773, -0.0011889015, 0.045667697, -0.1...   \n","3  [[-0.69215715, -0.052971497, 0.03891414, -0.02...   \n","4  [[-0.61126614, -0.005761562, -0.054692637, 0.0...   \n","\n","                         Image_Path  \n","0  human_annotated_images/10017.png  \n","1  human_annotated_images/10042.png  \n","2  human_annotated_images/10045.png  \n","3  human_annotated_images/10047.png  \n","4  human_annotated_images/10052.png  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# removed image path folder\n","df.rename(columns = {'Modified_Image_Path':'Image_Path'}, inplace = True)\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Printing an Image"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:29.699126Z","iopub.status.busy":"2024-09-25T16:26:29.698665Z","iopub.status.idle":"2024-09-25T16:26:32.194451Z","shell.execute_reply":"2024-09-25T16:26:32.193090Z","shell.execute_reply.started":"2024-09-25T16:26:29.699067Z"},"trusted":true},"outputs":[],"source":["# Printing Input Directories\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    print(dirname)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:32.196721Z","iopub.status.busy":"2024-09-25T16:26:32.196227Z","iopub.status.idle":"2024-09-25T16:26:32.202784Z","shell.execute_reply":"2024-09-25T16:26:32.201521Z","shell.execute_reply.started":"2024-09-25T16:26:32.196677Z"},"trusted":true},"outputs":[],"source":["DIRECTORY = 'dataset' "]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:32.205051Z","iopub.status.busy":"2024-09-25T16:26:32.204636Z","iopub.status.idle":"2024-09-25T16:26:32.359254Z","shell.execute_reply":"2024-09-25T16:26:32.357476Z","shell.execute_reply.started":"2024-09-25T16:26:32.205007Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Displaying an Image\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","# Example image path\n","image_path = os.path.join(DIRECTORY, df['Image_Path'][0])\n","\n","# Open the image\n","image = Image.open(image_path)\n","\n","# Display the image using Matplotlib\n","plt.imshow(image)\n","plt.axis('off')  # Hide axis\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Splitting Dataset into test and Train"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:26:32.363243Z","iopub.status.busy":"2024-09-25T16:26:32.361970Z","iopub.status.idle":"2024-09-25T16:27:08.448518Z","shell.execute_reply":"2024-09-25T16:27:08.446260Z","shell.execute_reply.started":"2024-09-25T16:26:32.363170Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train_text shape: (3202, 1, 768)\n","X_train_images shape: (3202, 256, 256, 3)\n","y_train shape: (3202,)\n","X_test_text shape: (801, 1, 768)\n","X_test_images shape: (801, 256, 256, 3)\n","y_test shape: (801,)\n"]}],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","\n","# Load BERT embeddings and image paths\n","X_text_embeddings = np.array(df['BERT_Embeddings'].tolist())\n","image_paths = df['Image_Path'].tolist()\n","\n","# Load images\n","X_images = []\n","for path in image_paths:\n","    path = DIRECTORY + path\n","    image = Image.open(path)\n","    #onvert image to numpy array and normalize if needed\n","    image_array = np.array(image) / 255.0\n","    X_images.append(image_array)\n","\n","# Convert lists to numpy arrays\n","X_text_embeddings = np.array(X_text_embeddings)\n","X_images = np.array(X_images)\n","\n","# Reshape or normalize if required (already done in the provided code)\n","\n","# Prepare target data (labels)\n","y = np.arange(len(df))  # Assuming each row corresponds to a unique label\n","\n","# Split the data into training and testing sets\n","X_train_text, X_test_text, X_train_images, X_test_images, y_train, y_test = train_test_split(\n","    X_text_embeddings, X_images, y, test_size=0.2, random_state=42\n",")\n","\n","# Display shapes of the data\n","print(\"X_train_text shape:\", X_train_text.shape)\n","print(\"X_train_images shape:\", X_train_images.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"X_test_text shape:\", X_test_text.shape)\n","print(\"X_test_images shape:\", X_test_images.shape)\n","print(\"y_test shape:\", y_test.shape)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:08.454581Z","iopub.status.busy":"2024-09-25T16:27:08.453852Z","iopub.status.idle":"2024-09-25T16:27:08.463109Z","shell.execute_reply":"2024-09-25T16:27:08.461735Z","shell.execute_reply.started":"2024-09-25T16:27:08.454509Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reshaped X_train_text shape: (3202, 768)\n","Reshaped X_test_text shape: (801, 768)\n"]}],"source":["# Reshape the text embeddings to remove the extra dimension\n","X_train_text = X_train_text.reshape(X_train_text.shape[0], -1)\n","X_test_text = X_test_text.reshape(X_test_text.shape[0], -1)\n","\n","# Display shapes after reshaping\n","print(\"Reshaped X_train_text shape:\", X_train_text.shape)\n","print(\"Reshaped X_test_text shape:\", X_test_text.shape)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:08.465119Z","iopub.status.busy":"2024-09-25T16:27:08.464716Z","iopub.status.idle":"2024-09-25T16:27:08.480683Z","shell.execute_reply":"2024-09-25T16:27:08.478865Z","shell.execute_reply.started":"2024-09-25T16:27:08.465062Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train_text shape: (3202, 768)\n","X_train_images shape: (3202, 256, 256, 3)\n","X_test_text shape: (801, 768)\n","X_test_images shape: (801, 256, 256, 3)\n"]}],"source":["# Display shapes of the data\n","print(\"X_train_text shape:\", X_train_text.shape)\n","print(\"X_train_images shape:\", X_train_images.shape)\n","\n","print(\"X_test_text shape:\", X_test_text.shape)\n","print(\"X_test_images shape:\", X_test_images.shape)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:08.482290Z","iopub.status.busy":"2024-09-25T16:27:08.481902Z","iopub.status.idle":"2024-09-25T16:27:08.507689Z","shell.execute_reply":"2024-09-25T16:27:08.506392Z","shell.execute_reply.started":"2024-09-25T16:27:08.482258Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([-0.5754481 ,  0.0189473 ,  0.11817609,  0.02992155,  0.65141094,\n","       -0.20927459,  0.04845341,  0.5410135 ,  0.13207452, -0.63569915,\n","        0.207006  , -0.64307034, -0.38915625,  0.16688353, -0.30772436,\n","        0.46441597,  0.28175345,  0.20655034,  0.0714353 ,  0.34022012,\n","        0.05433815, -0.29941747, -0.17494744,  0.60304934,  0.12055178,\n","       -0.01095621, -0.02932324,  0.07023944, -0.19566831,  0.08874706,\n","        0.6439936 , -0.04744988, -0.00477395, -0.67380816,  0.15863612,\n","       -0.2338918 ,  0.19983698, -0.14235647, -0.5475427 ,  0.14933665,\n","       -0.7797225 , -0.18704425,  0.05365221,  0.08347022, -0.0300341 ,\n","       -0.18644734,  0.5152984 , -0.21001706, -0.21902874,  0.3655471 ,\n","       -0.48608094, -0.05752416, -0.14547814,  0.0989761 ,  0.33760992,\n","        0.8571075 , -0.378471  , -0.23348029, -0.4961075 , -0.46169376,\n","        0.4204655 , -0.18531236,  0.44366038, -0.50126475,  0.26569808,\n","       -0.03627625,  0.44500747,  0.5008911 , -0.41431153,  0.0714153 ,\n","       -0.35047236, -0.1730873 ,  0.27332258, -0.22023228,  0.06421003,\n","       -0.10399906, -0.03892432,  0.2957332 ,  0.19769955, -0.15385637,\n","       -0.29190457,  0.24236777, -0.32660013,  0.6214714 , -0.08492417,\n","       -0.21469826, -0.2980385 , -0.03923772, -0.7338831 ,  0.9133425 ,\n","       -0.16374484, -0.228833  ,  0.10093482,  0.05267303,  0.35804528,\n","        0.08741653,  0.25631386,  0.30761686,  0.03444256,  0.5968548 ,\n","        0.00578304, -0.07729679,  0.14876193,  0.0607245 ,  0.09437284,\n","       -0.43237275,  0.22763082, -0.23993339,  0.14797753,  0.36779073,\n","       -0.09939353, -0.3613384 ,  0.07963001, -0.21547528, -0.05586934,\n","        0.34242985,  0.20004375, -0.18293887,  0.14909098,  0.2665437 ,\n","        0.16316722,  0.0192323 , -0.0360994 ,  0.7035587 , -0.11102749,\n","        0.057201  , -0.24894293,  0.424746  , -0.2886099 , -0.30141714,\n","        0.12507857,  0.16251379,  0.34462082,  0.10543445, -0.10136723,\n","        0.39591953, -0.18888488, -0.10704794, -0.34078342,  0.48183125,\n","        0.25652066, -0.31015384,  0.35055947,  0.00829216, -0.01282884,\n","       -0.18792814, -0.25439608, -0.44483057, -0.09776392,  0.50225323,\n","        0.312329  ,  0.10934666,  0.25953197, -0.23863783, -0.09140077,\n","       -0.09288926, -0.19413343,  0.3549167 , -0.2596096 , -0.02861941,\n","        0.6388126 , -0.05447589, -0.17757696,  0.21514729, -0.10417841,\n","        0.30410987,  0.11357082,  0.5833514 , -0.43077257,  0.07600305,\n","       -0.33651778, -0.23797198,  0.8820481 , -0.09489372, -0.10669566,\n","       -0.13880251,  0.12255583,  0.2134936 ,  0.3765071 , -0.18764089,\n","       -0.5952923 ,  0.25893423, -0.24886543,  0.05211594,  0.6510507 ,\n","       -0.2961731 ,  0.5044235 , -0.357192  ,  0.00633896,  0.07436988,\n","        0.3427082 , -0.5423686 , -0.2867854 ,  0.02483355,  0.23905557,\n","       -0.3320396 , -0.23249745, -0.51313764, -0.5610836 ,  0.02270452,\n","        0.07921848, -0.06594992,  0.79860157,  0.26125544, -0.09365103,\n","       -0.4987985 , -0.05795961, -0.13297927,  0.2077885 ,  0.22564155,\n","       -0.06260696,  0.14493236,  0.09982064,  0.4570575 ,  0.16220497,\n","       -0.10625229,  0.175133  , -0.50295234,  0.44199672, -0.2559827 ,\n","        0.49437323,  0.10456964, -0.52650154,  0.63478553, -0.41534883,\n","        1.0645694 ,  0.11740503, -0.56049716,  0.0908746 ,  0.7129161 ,\n","       -0.13157383, -0.527778  ,  0.8022525 , -0.24632089, -0.30801755,\n","        0.26049098, -0.3362108 ,  0.2871287 ,  0.37712282, -0.40672636,\n","       -0.44092757,  0.49361646,  0.53776675, -0.13927118,  0.30915943,\n","        0.0087682 , -0.10088401, -0.18527056, -0.4062815 , -0.2610215 ,\n","       -0.4998008 , -0.20668755,  0.25629324, -0.68199736, -0.04970024,\n","       -0.4017093 ,  0.07906473, -0.22882038,  0.03992737, -0.08385258,\n","        0.17112567, -0.00455584,  0.2705676 ,  0.14184313, -0.37877846,\n","       -0.52480906,  0.228357  ,  0.8262507 , -0.09961925,  0.02217762,\n","        0.00860662, -0.08130046,  0.09301588,  0.6363797 , -0.45304602,\n","       -0.0238364 ,  0.36056682,  0.0592916 , -0.13429146, -0.5489628 ,\n","        0.30645838,  0.6704116 ,  0.12825035,  0.09252219,  0.12737769,\n","       -0.46711525,  0.28910694,  0.05636906, -0.33135918, -0.5218477 ,\n","       -0.01795679,  0.19199689, -0.1630251 , -0.42773396,  0.14213113,\n","       -0.15989837, -0.2874534 ,  0.06133073,  0.33316746, -0.14138444,\n","       -0.31976607, -0.21269123,  0.02955413,  0.03808765, -0.05902842,\n","       -0.0626005 , -0.08027871, -0.4580564 , -3.3100572 ,  0.31584838,\n","        0.06307743,  0.0591811 , -0.05391124, -0.28823304, -0.04926568,\n","       -0.03323754, -0.73939764,  0.09079885, -0.20429334, -0.30067104,\n","        0.63420755,  0.06416832,  0.43173966, -0.14856964, -0.47975716,\n","       -0.19743806, -0.0518141 ,  0.25625098, -0.3049817 , -0.42107168,\n","        0.20669341, -0.3556082 ,  0.7553556 ,  0.5475307 , -0.3838568 ,\n","       -0.2824743 , -0.33607468, -0.44259962,  0.15889074, -0.14398961,\n","       -0.00357509,  0.3337805 ,  0.36831212, -0.35687184,  0.07855239,\n","       -0.47017103, -0.24079196, -0.22119892,  0.25807756, -0.7542628 ,\n","       -0.04222978, -0.46317   ,  0.8865753 , -0.1938586 ,  0.20558605,\n","       -0.4555171 ,  0.1510828 ,  0.3626992 ,  0.38436124,  0.0448565 ,\n","       -0.09861397,  0.07297494, -0.2062308 , -0.11954276,  0.53088784,\n","        0.45732367, -0.20518456, -0.41735145, -0.10361478, -0.3014218 ,\n","       -0.5679759 , -0.18024196,  0.13040507, -0.6294914 , -0.35289747,\n","        0.4353009 ,  0.16946438,  0.38318646,  0.02536068,  0.5078607 ,\n","       -0.3669549 , -0.41965786, -0.21722758, -0.64630276,  0.17145137,\n","       -0.36464292, -0.05053375, -0.35406837,  0.1433597 , -0.5591974 ,\n","       -0.00611942,  0.035292  ,  0.11607687, -0.7107852 ,  0.23417181,\n","        0.11890043, -0.3108511 , -0.13401023,  0.0940587 ,  0.4325833 ,\n","       -0.17351831, -0.09384654,  0.23508716, -0.36447322,  0.35907218,\n","       -0.4000097 ,  0.25951424, -0.43179986,  0.06674982, -0.19591744,\n","        0.26710084, -0.04274069,  0.01433644, -0.21628375,  0.0246923 ,\n","        0.3466762 , -0.21677975, -0.05623873,  0.1726331 , -0.78465664,\n","        0.46547312, -0.26968226, -0.09451837, -0.26334497,  0.05385775,\n","        0.360864  , -0.36448348, -0.19562842,  0.05373451,  0.4388722 ,\n","       -0.2750612 , -0.22732306, -0.4399488 ,  0.24133566,  0.01216306,\n","       -0.33920246, -0.0836777 ,  0.25127804, -0.32185587, -0.14194334,\n","       -0.02678075,  0.34835204,  0.0470278 ,  0.2524112 , -0.20394126,\n","       -0.9437069 ,  0.1490453 ,  0.10604335,  0.11228458,  0.06708919,\n","       -0.09969863,  0.01090329, -0.35708576,  0.7570498 ,  0.25873902,\n","       -0.12201381, -0.19069283, -0.09525031, -0.4994209 , -0.2936042 ,\n","       -0.14331548, -0.20655648,  0.22837226,  0.18614855, -0.19811778,\n","        0.26111552, -0.2134996 , -0.5683189 ,  0.2140863 ,  0.01720108,\n","        0.49898186,  0.05033354, -0.38731897,  0.9805871 ,  0.00901103,\n","        0.33745778, -0.02557288,  0.32526526,  0.24776721, -0.5635481 ,\n","       -0.00744236, -0.2809889 , -0.20421298,  0.45483425, -0.16554044,\n","       -0.15523623, -0.05704835,  0.15390766, -0.12745461,  0.0730636 ,\n","       -0.15382247, -0.365741  ,  0.14953303, -0.03980146,  0.02564276,\n","       -0.45969567,  0.05728323,  0.25899744,  0.22006917,  0.11074182,\n","       -0.22594346,  0.06491846, -0.22608571, -0.55813426,  0.23932382,\n","        0.34912273, -0.02293242,  0.36318374,  0.27112707, -0.06324616,\n","       -0.44698644,  0.13549972,  0.21545137, -0.12955774,  0.4214165 ,\n","        0.3505492 ,  0.16976549,  0.3754776 , -0.56826293, -0.06183172,\n","       -0.5452734 , -0.12367322, -0.23171555, -0.477583  , -0.14452732,\n","       -0.12092187, -0.15712288, -0.16752239, -0.32302138, -0.11017393,\n","        0.18877631, -0.31559405, -0.65560085,  0.09663997,  0.32459775,\n","       -0.03093191, -0.1750226 , -0.5736046 ,  0.6593784 , -0.40957972,\n","        0.16900577, -0.00678745,  0.02114959,  0.09283423, -0.20349023,\n","       -0.92744297,  0.24543837,  0.289408  , -0.01611829, -0.17837858,\n","       -0.4534847 , -0.19522385,  0.2129491 , -0.02786582, -0.04448413,\n","        0.14492184, -0.00847939,  0.53806144, -0.13932036, -0.1048016 ,\n","        0.2730859 , -0.35071525,  0.10805654, -0.7805645 , -0.322231  ,\n","        0.09672112, -0.11379978, -0.02015167, -0.2592481 , -0.1806362 ,\n","       -0.10968934,  0.36508554,  0.2763766 ,  0.15791301, -0.10615356,\n","       -0.00900127, -0.13556975, -0.42808616,  0.36155853, -0.34430325,\n","        0.01082182, -0.38618368,  0.0131722 ,  0.38197628, -0.23198855,\n","       -0.45656937,  0.26088357, -0.55959177, -0.40975258, -0.10721393,\n","       -0.03349166, -0.04774118,  0.09792082, -0.09435553, -0.29775217,\n","        0.4820078 , -0.18036966, -0.22504319,  0.27546215, -0.07967655,\n","        0.1620081 ,  0.10541795,  0.02982367,  0.23623957,  0.5733647 ,\n","        0.25618628,  0.04920441, -0.17383501,  0.0244759 , -0.0922219 ,\n","       -0.40381223,  0.27199945, -0.13184987,  0.24759655,  0.09231931,\n","       -0.54188436, -0.04435676,  0.29133722, -0.18525267, -0.45178273,\n","        0.67244494,  0.39480105, -0.7640701 , -0.15973412, -0.26980117,\n","       -0.04738321,  0.10639863, -0.19836739,  0.21385029, -0.09024748,\n","        0.8583223 ,  0.3004621 ,  0.13861758,  0.59524846, -0.2974639 ,\n","        0.02505656, -0.25067103,  0.19936238, -0.09546243,  0.24764925,\n","       -0.3246696 ,  0.38646147, -0.02610948, -0.04818762, -0.5730099 ,\n","        0.05359725,  0.2663716 , -0.3651441 , -0.26788965,  0.18384476,\n","        0.29429373,  0.5645809 ,  0.6358598 ,  0.27478543,  0.25341642,\n","       -0.44970647,  0.8695551 ,  0.16464233,  0.12956004,  0.10247046,\n","        0.14114727, -0.35181305, -0.08469529,  0.72639686,  0.45296422,\n","        0.15686154, -0.05036012,  1.044883  ,  0.52272844,  0.24295035,\n","        0.58987004, -0.52488935, -0.290401  ,  0.10190949,  0.25984767,\n","       -0.61943376, -0.29755563,  0.28262126,  0.01946517,  0.31395847,\n","        0.2248702 , -0.35801992, -0.05760279,  1.2359482 , -0.05548104,\n","        0.06078491, -0.16257118,  0.02677738,  0.40401083,  0.13122945,\n","       -0.56819594, -0.7264039 ,  0.08814319, -0.37416187,  0.24884188,\n","        0.2590642 ,  0.02926009, -0.28651896,  0.08618268, -0.17162366,\n","        0.47692674, -0.60009587, -0.10091455, -0.61379206,  0.438452  ,\n","       -0.01318318,  0.8650698 , -0.06298966,  0.29127526, -0.1730495 ,\n","       -0.09404317, -0.1505509 , -0.03297953,  0.07335895, -0.10079341,\n","        0.14204668, -0.03638513,  0.02698858,  0.09550305,  0.4353172 ,\n","       -0.1689573 , -0.01921727,  0.23209265, -0.21497707,  0.17402475,\n","       -0.14347443, -0.40463868,  0.18255413, -0.22065195, -0.36481768,\n","       -0.09638709,  0.03101354, -0.36168444, -0.48371628,  0.22167055,\n","       -0.01860575,  0.17741694, -0.17981331, -0.38673818,  0.31815076,\n","       -0.11089641,  0.49114877, -0.48888546, -0.39990515, -0.04676212,\n","        0.14191984, -0.18312635, -0.2846807 ,  0.47055677,  0.45524302,\n","       -0.05592088,  0.22505474,  0.4283567 , -0.227645  , -0.32102665,\n","       -0.5122114 ,  0.20375803, -0.35879934,  0.05686883, -0.2556379 ,\n","        0.16593324, -0.51783425, -0.49138048, -0.06027102, -0.16635352,\n","        0.22152266,  0.4652689 ,  0.08877223], dtype=float32)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# VERIFICATION\n","X_train_text[0]"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:08.509711Z","iopub.status.busy":"2024-09-25T16:27:08.509317Z","iopub.status.idle":"2024-09-25T16:27:08.781656Z","shell.execute_reply":"2024-09-25T16:27:08.780460Z","shell.execute_reply.started":"2024-09-25T16:27:08.509665Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# displaying images\n","data = X_train_images[2]\n","from matplotlib import pyplot as plt\n","plt.imshow(data, interpolation='nearest')\n","plt.show()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:08.783595Z","iopub.status.busy":"2024-09-25T16:27:08.783233Z","iopub.status.idle":"2024-09-25T16:27:09.464508Z","shell.execute_reply":"2024-09-25T16:27:09.462937Z","shell.execute_reply.started":"2024-09-25T16:27:08.783564Z"},"trusted":true},"outputs":[],"source":["# DO NOT RUN THIS , skip to next cell.\n","import cv2\n","resized_images = []\n","\n","# Define the new dimensions\n","new_width = 64\n","new_height = 64\n","\n","for image in X_train_images:\n","    resized_img = cv2.resize(image, (new_width, new_height))  \n","    resized_images.append(resized_img)\n","\n","# Now, resized_images will contain your resized images ready for passing into GAN\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:09.467101Z","iopub.status.busy":"2024-09-25T16:27:09.466608Z","iopub.status.idle":"2024-09-25T16:27:09.475698Z","shell.execute_reply":"2024-09-25T16:27:09.474120Z","shell.execute_reply.started":"2024-09-25T16:27:09.467038Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(3202, 256, 256, 3)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["X_train_images.shape"]},{"cell_type":"markdown","metadata":{},"source":["# Applying CGANs"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:09.477974Z","iopub.status.busy":"2024-09-25T16:27:09.477544Z","iopub.status.idle":"2024-09-25T16:27:19.185105Z","shell.execute_reply":"2024-09-25T16:27:19.184116Z","shell.execute_reply.started":"2024-09-25T16:27:09.477939Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-09-25 16:27:11.616074: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-25 16:27:11.616256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-25 16:27:11.762532: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import skimage as ski\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:19.188115Z","iopub.status.busy":"2024-09-25T16:27:19.186860Z","iopub.status.idle":"2024-09-25T16:27:19.204400Z","shell.execute_reply":"2024-09-25T16:27:19.203314Z","shell.execute_reply.started":"2024-09-25T16:27:19.188043Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, Model\n","\n","# Define Generator\n","def build_generator():\n","    input_text = layers.Input(shape=(768,))\n","    x = layers.Dense(256, activation='relu')(input_text)\n","    x = layers.Dense(256, activation='relu')(x)\n","    x = layers.Reshape((16, 16, 1))(x)\n","    \n","    input_noise = layers.Input(shape=(100,))\n","    y = layers.Dense(256 * 16 * 16, activation='relu')(input_noise)\n","    y = layers.Reshape((16, 16, 256))(y)\n","    \n","    concatenated = layers.Concatenate(axis=-1)([x, y])\n","    \n","    # Conv2DTranspose layers to progressively upsample to 256x256\n","    x = layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', activation='relu')(concatenated)  # 16x16 -> 32x32\n","    x = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)              # 32x32 -> 64x64\n","    x = layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)              # 64x64 -> 128x128\n","    output = layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', activation='sigmoid')(x)        # 128x128 -> 256x256\n","    \n","    model = Model(inputs=[input_text, input_noise], outputs=output)\n","    return model\n","\n","# Define Discriminator\n","def build_discriminator():\n","    input_image = layers.Input(shape=(256, 256, 3))\n","    x = layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', activation='relu')(input_image)\n","    x = layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)\n","    x = layers.Flatten()(x)\n","    x = layers.Dense(1, activation='sigmoid')(x)\n","    \n","    model = Model(inputs=input_image, outputs=x)\n","    return model"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:19.206370Z","iopub.status.busy":"2024-09-25T16:27:19.205866Z","iopub.status.idle":"2024-09-25T16:27:19.435649Z","shell.execute_reply":"2024-09-25T16:27:19.434541Z","shell.execute_reply.started":"2024-09-25T16:27:19.206329Z"},"trusted":true},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n","<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n","\n"," input_layer          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n","\n"," dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n","\n"," input_layer_1        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n","\n"," dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span>  dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n","\n"," dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65536</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,619,136</span>  input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n","\n"," reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n","\n"," reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n","                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                                             \n","\n"," concatenate          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span>)                           reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n","\n"," conv2d_transpose     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">822,528</span>  concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                             \n","\n"," conv2d_transpose_1   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">204,864</span>  conv2d_transpose \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                                              \n","\n"," conv2d_transpose_2   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,       <span style=\"color: #00af00; text-decoration-color: #00af00\">51,232</span>  conv2d_transpose \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                                              \n","\n"," conv2d_transpose_3   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">2,403</span>  conv2d_transpose \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                                               \n","\n","</pre>\n"],"text/plain":["\n","\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n","\n"," input_layer          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n"," (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n","\n"," dense (\u001b[38;5;33mDense\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m196,864\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n","\n"," input_layer_1        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n"," (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n","\n"," dense_1 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            \u001b[38;5;34m65,792\u001b[0m  dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n","\n"," dense_2 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65536\u001b[0m)       \u001b[38;5;34m6,619,136\u001b[0m  input_layer_1[\u001b[38;5;34m0\u001b[0m] \n","\n"," reshape (\u001b[38;5;33mReshape\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m)           \u001b[38;5;34m0\u001b[0m  dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n","\n"," reshape_1 (\u001b[38;5;33mReshape\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,              \u001b[38;5;34m0\u001b[0m  dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n","                      \u001b[38;5;34m256\u001b[0m)                                             \n","\n"," concatenate          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,              \u001b[38;5;34m0\u001b[0m  reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    \n"," (\u001b[38;5;33mConcatenate\u001b[0m)        \u001b[38;5;34m257\u001b[0m)                           reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n","\n"," conv2d_transpose     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,        \u001b[38;5;34m822,528\u001b[0m  concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n"," (\u001b[38;5;33mConv2DTranspose\u001b[0m)    \u001b[38;5;34m128\u001b[0m)                                             \n","\n"," conv2d_transpose_1   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,        \u001b[38;5;34m204,864\u001b[0m  conv2d_transpose \n"," (\u001b[38;5;33mConv2DTranspose\u001b[0m)    \u001b[38;5;34m64\u001b[0m)                                              \n","\n"," conv2d_transpose_2   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,       \u001b[38;5;34m51,232\u001b[0m  conv2d_transpose \n"," (\u001b[38;5;33mConv2DTranspose\u001b[0m)    \u001b[38;5;34m32\u001b[0m)                                              \n","\n"," conv2d_transpose_3   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,        \u001b[38;5;34m2,403\u001b[0m  conv2d_transpose \n"," (\u001b[38;5;33mConv2DTranspose\u001b[0m)    \u001b[38;5;34m3\u001b[0m)                                               \n","\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,962,819</span> (30.38 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,962,819\u001b[0m (30.38 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,962,819</span> (30.38 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,962,819\u001b[0m (30.38 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["generator = build_generator()\n","generator.summary()"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:19.438280Z","iopub.status.busy":"2024-09-25T16:27:19.437285Z","iopub.status.idle":"2024-09-25T16:27:19.453427Z","shell.execute_reply":"2024-09-25T16:27:19.452254Z","shell.execute_reply.started":"2024-09-25T16:27:19.438237Z"},"trusted":true},"outputs":[],"source":["class CGAN(Model):\n","    def __init__(self, generator, discriminator):\n","        super(CGAN, self).__init__()\n","        self.generator = generator\n","        self.discriminator = discriminator\n","\n","    def compile(self, g_optimizer, d_optimizer, loss_fn):\n","        super(CGAN, self).compile()\n","        self.g_optimizer = g_optimizer\n","        self.d_optimizer = d_optimizer\n","        self.loss_fn = loss_fn\n","\n","    def call(self, inputs):\n","        text, noise = inputs\n","        generated_images = self.generator([text, noise])\n","        return self.discriminator(generated_images)\n","\n","    def train_step(self, data):\n","        text_embeddings, real_images = data[0]\n","        batch_size = tf.shape(real_images)[0]\n","        print(batch_size)\n","        noise = tf.random.normal((batch_size, 100))\n","\n","        # Train discriminator\n","        with tf.GradientTape() as tape:\n","            generated_images = self.generator([text_embeddings, noise], training=True)\n","            real_output = self.discriminator(real_images, training=True)\n","            fake_output = self.discriminator(generated_images, training=True)\n","            d_loss_real = self.loss_fn(tf.ones_like(real_output), real_output)\n","            d_loss_fake = self.loss_fn(tf.zeros_like(fake_output), fake_output)\n","            d_loss = d_loss_real + d_loss_fake\n","\n","        d_gradients = tape.gradient(d_loss, self.discriminator.trainable_variables)\n","        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n","\n","        # Train generator\n","        with tf.GradientTape() as tape:\n","            generated_images = self.generator([text_embeddings, noise], training=True)\n","            fake_output = self.discriminator(generated_images, training=True)\n","            g_loss = self.loss_fn(tf.ones_like(fake_output), fake_output)\n","\n","        g_gradients = tape.gradient(g_loss, self.generator.trainable_variables)\n","        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n","\n","        return {'d_loss': d_loss, 'g_loss': g_loss}\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:19.455266Z","iopub.status.busy":"2024-09-25T16:27:19.454866Z","iopub.status.idle":"2024-09-25T16:27:19.470793Z","shell.execute_reply":"2024-09-25T16:27:19.469377Z","shell.execute_reply.started":"2024-09-25T16:27:19.455235Z"},"trusted":true},"outputs":[],"source":["real_images = X_train_images[:100]\n","text_embeddings = X_train_text[:100]"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:19.472515Z","iopub.status.busy":"2024-09-25T16:27:19.472171Z","iopub.status.idle":"2024-09-25T16:27:19.488519Z","shell.execute_reply":"2024-09-25T16:27:19.487450Z","shell.execute_reply.started":"2024-09-25T16:27:19.472488Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(100, 256, 256, 3)\n","(100, 768)\n"]}],"source":["print(real_images.shape)\n","print(text_embeddings.shape)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:19.490823Z","iopub.status.busy":"2024-09-25T16:27:19.490367Z","iopub.status.idle":"2024-09-25T16:27:19.503173Z","shell.execute_reply":"2024-09-25T16:27:19.501976Z","shell.execute_reply.started":"2024-09-25T16:27:19.490783Z"},"trusted":true},"outputs":[{"data":{"text/plain":["numpy.ndarray"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["type(real_images)\n","type(text_embeddings)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:27:19.504777Z","iopub.status.busy":"2024-09-25T16:27:19.504433Z","iopub.status.idle":"2024-09-25T16:35:23.815103Z","shell.execute_reply":"2024-09-25T16:35:23.813349Z","shell.execute_reply.started":"2024-09-25T16:27:19.504748Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py:695: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n","  output, from_logits = _get_logits(\n"]},{"name":"stdout","output_type":"stream","text":["Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n","\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5s/step - d_loss: 2.0853 - g_loss: 0.5442 - loss: 0.0000e+00\n","Epoch 2/15\n","\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 1.1339 - g_loss: 0.5920 - loss: 0.0000e+00\n","Epoch 3/15\n","\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5s/step - d_loss: 0.6783 - g_loss: 1.3047 - loss: 0.0000e+00\n","Epoch 4/15\n","\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 0.2881 - g_loss: 2.2170 - loss: 0.0000e+00\n","Epoch 5/15\n","\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5s/step - d_loss: 0.2265 - g_loss: 3.3556 - loss: 0.0000e+00\n","Epoch 6/15\n","\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 0.9529 - g_loss: 2.2844 - loss: 0.0000e+00\n","Epoch 7/15\n","\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 0.1851 - g_loss: 3.7187 - loss: 0.0000e+00\n","Epoch 8/15\n","\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 6s/step - d_loss: 0.0611 - g_loss: 3.7983 - loss: 0.0000e+00\n","Epoch 9/15\n","\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 0.1723 - g_loss: 2.9091 - loss: 0.0000e+00\n","Epoch 10/15\n","\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5s/step - d_loss: 0.1209 - g_loss: 3.9403 - loss: 0.0000e+00\n","Epoch 11/15\n","\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 1.0487 - g_loss: 2.5071 - loss: 0.0000e+00\n","Epoch 12/15\n","\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 0.4697 - g_loss: 5.0765 - loss: 0.0000e+00\n","Epoch 13/15\n","\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - d_loss: 1.8181 - g_loss: 2.3165 - loss: 0.0000e+00\n","Epoch 14/15\n","\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5s/step - d_loss: 0.0437 - g_loss: 4.6444 - loss: 0.0000e+00\n","Epoch 15/15\n","\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5s/step - d_loss: 0.0651 - g_loss: 3.3345 - loss: 0.0000e+00\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x792ef6909e40>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Build and compile models\n","generator = build_generator()\n","discriminator = build_discriminator()\n","cgan = CGAN(generator, discriminator)\n","cgan.compile(\n","    g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n","    d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n","    loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",")\n","\n","# Assuming text_embeddings and real_images are NumPy arrays\n","data = (text_embeddings, real_images)\n","# print(\"This is from here\")\n","# print(data)\n","# Train CGAN\n","cgan.fit(data, epochs=15, batch_size=32)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Codium Code"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:51:48.551425Z","iopub.status.busy":"2024-09-25T16:51:48.550793Z","iopub.status.idle":"2024-09-25T16:51:48.572954Z","shell.execute_reply":"2024-09-25T16:51:48.571369Z","shell.execute_reply.started":"2024-09-25T16:51:48.551380Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","\n","# Generator model\n","class Generator(nn.Module):\n","    def __init__(self, embedding_dim, image_channels=3):\n","        super(Generator, self).__init__()\n","        \n","        self.embedding_dim = embedding_dim\n","        \n","        self.fc = nn.Linear(embedding_dim, 256*256*3)\n","        self.conv_blocks = nn.Sequential(\n","            nn.Conv2d(image_channels + 100, 64, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, image_channels, kernel_size=3, stride=1, padding=1),\n","            nn.Tanh()\n","        )\n","    \n","    def forward(self, noise, text_embeddings):\n","        x = self.fc(text_embeddings)\n","        x = x.view(x.size(0), 3, 256, 256)  # Reshape the output to match the size of the image\n","        noise = noise.view(noise.size(0), 100, 1, 1)  # Expand noise to match the spatial dimensions of x\n","        noise = noise.repeat(1, 1, 256, 256)  # Repeat noise to match the spatial dimensions of x\n","        x = torch.cat([x, noise], dim=1)  # Concatenate noise with the image along the channel dimension\n","        x = self.conv_blocks(x)\n","        return x\n","\n","# Discriminator model\n","class Discriminator(nn.Module):\n","    def __init__(self, image_channels=3, embedding_dim=768):\n","        super(Discriminator, self).__init__()\n","\n","        # Project the text embeddings to match the image channels (3 channels)\n","        self.embedding_conv = nn.Conv2d(embedding_dim, image_channels, kernel_size=1)\n","\n","        self.conv_blocks = nn.Sequential(\n","            nn.Conv2d(image_channels * 2, 64, kernel_size=3, stride=2, padding=1),  # Image + Embedding channels\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # Add more Conv2d layers as needed\n","        )\n","        \n","        self.fc = nn.Linear(64 * 128 * 128, 1)\n","    \n","    def forward(self, images, text_embeddings):\n","        # Corrected: Assuming images are in shape (batch_size, height, width, channels), permute them properly.\n","        images = images.permute(0, 3, 1, 2)  # Correct permutation: (batch_size, channels, height, width)\n","        \n","        # Project text embeddings to image dimensions\n","        text_embeddings = text_embeddings.view(text_embeddings.size(0), text_embeddings.size(1), 1, 1)\n","        text_embeddings = text_embeddings.repeat(1, 1, 256, 256)  # Shape: (batch_size, 768, 256, 256)\n","        \n","        # Apply the 1x1 convolution to reduce the channels of text embeddings\n","        projected_embeddings = self.embedding_conv(text_embeddings)  # Shape: (batch_size, 3, 256, 256)\n","        \n","        # Ensure both images and projected embeddings have the same shape\n","        if images.shape != projected_embeddings.shape:\n","            raise RuntimeError(f\"Shape mismatch: images {images.shape}, embeddings {projected_embeddings.shape}\")\n","        \n","        # Concatenate images and projected embeddings along the channel dimension\n","        x = torch.cat([images, projected_embeddings], dim=1)  # Shape: (batch_size, 6, 256, 256)\n","        \n","        # Pass through the convolutional layers\n","        x = self.conv_blocks(x)\n","        x = x.view(x.size(0), -1)  # Flatten for fully connected layer\n","        \n","        # Compute validity\n","        validity = self.fc(x)\n","        return validity"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:51:51.860117Z","iopub.status.busy":"2024-09-25T16:51:51.859163Z","iopub.status.idle":"2024-09-25T16:51:52.543680Z","shell.execute_reply":"2024-09-25T16:51:52.542472Z","shell.execute_reply.started":"2024-09-25T16:51:51.860041Z"},"trusted":true},"outputs":[],"source":["# Custom Dataset\n","class CustomDataset(Dataset):\n","    def __init__(self, real_images, text_embeddings):\n","        self.real_images = real_images\n","        self.text_embeddings = text_embeddings\n","    \n","    def __len__(self):\n","        return len(self.real_images)\n","    \n","    def __getitem__(self, idx):\n","        image = torch.tensor(self.real_images[idx], dtype=torch.float32)\n","        embedding = torch.tensor(self.text_embeddings[idx], dtype=torch.float32)\n","        return image, embedding\n","\n","# Placeholder for actual data (replace with your real data)\n","real_images = np.random.randn(100, 256, 256, 3).astype(np.float32)  # 100 RGB images\n","text_embeddings = np.random.randn(100, 768).astype(np.float32)  # 100 text embeddings\n","\n","# Create an instance of the CustomDataset\n","custom_dataset = CustomDataset(real_images, text_embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:51:55.601449Z","iopub.status.busy":"2024-09-25T16:51:55.600114Z"},"trusted":true},"outputs":[],"source":["# Create a PyTorch DataLoader to iterate over the dataset\n","batch_size = 16\n","data_loader = DataLoader(dataset=custom_dataset, batch_size=batch_size, shuffle=True)\n","\n","# Instantiate the Generator and Discriminator models\n","generator = Generator(embedding_dim=768)\n","discriminator = Discriminator()\n","\n","# Define optimizers for Generator and Discriminator\n","optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","\n","# Training loop\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    for i, (images, text_embeddings) in enumerate(data_loader):\n","        # Train the Discriminator\n","        optimizer_D.zero_grad()\n","        \n","        # Generate fake images from Generator\n","        noise = torch.randn(batch_size, 100)\n","        fake_images = generator(noise, text_embeddings)\n","        \n","        # Compute Discriminator loss\n","        real_loss = discriminator(images, text_embeddings)\n","        fake_loss = discriminator(fake_images, text_embeddings)\n","        d_loss = -torch.mean(real_loss) + torch.mean(fake_loss)\n","        \n","        d_loss.backward()\n","        optimizer_D.step()\n","        \n","        # Train the Generator\n","        optimizer_G.zero_grad()\n","        \n","        # Generate fake images from Generator\n","        noise = torch.randn(batch_size, 100)\n","        fake_images = generator(noise, text_embeddings)\n","        \n","        # Compute Generator loss\n","        g_loss = -torch.mean(discriminator(fake_images, text_embeddings))\n","        \n","        g_loss.backward()\n","        optimizer_G.step()"]},{"cell_type":"markdown","metadata":{},"source":["# ATTEMPT 3"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:52:08.446994Z","iopub.status.busy":"2024-09-25T16:52:08.445930Z","iopub.status.idle":"2024-09-25T16:52:08.864704Z","shell.execute_reply":"2024-09-25T16:52:08.863153Z","shell.execute_reply.started":"2024-09-25T16:52:08.446949Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'X_train_images' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m real_images \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_images\u001b[49m[:\u001b[38;5;241m100\u001b[39m]\n\u001b[1;32m      2\u001b[0m text_embeddings \u001b[38;5;241m=\u001b[39m X_train_text[:\u001b[38;5;241m100\u001b[39m]\n","\u001b[0;31mNameError\u001b[0m: name 'X_train_images' is not defined"]}],"source":["real_images = X_train_images[:100]\n","text_embeddings = X_train_text[:100]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-25T16:35:44.924959Z","iopub.status.idle":"2024-09-25T16:35:44.925469Z","shell.execute_reply":"2024-09-25T16:35:44.925258Z","shell.execute_reply.started":"2024-09-25T16:35:44.925239Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","# Define the target image resolution\n","TARGET_HEIGHT, TARGET_WIDTH = 128, 128\n","\n","# Function to resize images\n","def resize_images(images):\n","    resized_images = []\n","    for image in images:\n","        resized_image = cv2.resize(image, (TARGET_WIDTH, TARGET_HEIGHT))\n","        resized_images.append(resized_image)\n","    return np.array(resized_images)\n","\n","# Example usage:\n","real_images = resize_images(real_images)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-25T16:35:44.926928Z","iopub.status.idle":"2024-09-25T16:35:44.927417Z","shell.execute_reply":"2024-09-25T16:35:44.927210Z","shell.execute_reply.started":"2024-09-25T16:35:44.927191Z"},"trusted":true},"outputs":[],"source":["real_images.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-25T16:35:44.929637Z","iopub.status.idle":"2024-09-25T16:35:44.930274Z","shell.execute_reply":"2024-09-25T16:35:44.929906Z","shell.execute_reply.started":"2024-09-25T16:35:44.929887Z"},"trusted":true},"outputs":[],"source":["# Modify the build_generator function to accept resized images\n","def build_generator():\n","    text_embedding_input = Input(shape=(TEXT_EMBEDDING_DIM,))\n","    latent_input = Input(shape=(LATENT_DIM,))\n","    \n","    # Concatenate text embedding and latent noise vector\n","    merged_input = Concatenate()([text_embedding_input, latent_input])\n","    \n","    # Fully connected layer to map to initial shape\n","    x = Dense(32 * 32 * 128, activation='relu')(merged_input)  # Adjust based on the size of your resized images\n","    x = Reshape((32, 32, 128))(x)  # Adjust based on the size of your resized images\n","    \n","    # Convolutional layers to upsample the image\n","    x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)\n","    x = Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)\n","    generated_image = Conv2DTranspose(IMAGE_CHANNELS, (5, 5), strides=(2, 2), padding='same', activation='tanh')(x)\n","\n","    model = Model(inputs=[text_embedding_input, latent_input], outputs=generated_image)\n","    return model\n","\n","# Modify the build_discriminator function to accept resized images\n","def build_discriminator():\n","    image_input = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))  # Adjust based on the size of your resized images\n","    text_embedding_input = Input(shape=(TEXT_EMBEDDING_DIM,))\n","    \n","    # Embedding layer to map text embedding to the same space as image\n","    embedded_text = Dense(IMAGE_HEIGHT * IMAGE_WIDTH * IMAGE_CHANNELS, activation='relu')(text_embedding_input)  # Adjust based on the size of your resized images\n","    embedded_text = Reshape((IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))(embedded_text)  # Adjust based on the size of your resized images\n","    \n","    # Resize the embedded text to match the spatial dimensions of the image\n","    embedded_text = tf.image.resize(embedded_text, (IMAGE_HEIGHT, IMAGE_WIDTH), method='nearest')\n","    \n","    # Concatenate image and text embedding\n","    merged_input = Concatenate()([image_input, embedded_text])\n","    \n","    # Convolutional layers to downsample the image\n","    x = Conv2D(32, (5, 5), strides=(2, 2), padding='same', activation='relu')(merged_input)\n","    x = Conv2D(64, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)\n","    x = Conv2D(128, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)\n","    flattened = Flatten()(x)\n","    \n","    # Fully connected layer for binary classification\n","    discriminator_output = Dense(1, activation='sigmoid')(flattened)\n","\n","    model = Model(inputs=[image_input, text_embedding_input], outputs=discriminator_output)\n","    return model\n","\n","# Create placeholders for text embeddings and latent vectors\n","text_embedding_input = Input(shape=(TEXT_EMBEDDING_DIM,))\n","latent_input = Input(shape=(LATENT_DIM,))\n","\n","# Build and compile the models\n","generator = build_generator()\n","discriminator = build_discriminator()\n","\n","generator_optimizer = Adam(lr=0.0002, beta_1=0.5)\n","discriminator_optimizer = Adam(lr=0.0002, beta_1=0.5)\n","\n","generator.compile(loss='binary_crossentropy', optimizer=generator_optimizer)\n","discriminator.compile(loss='binary_crossentropy', optimizer=discriminator_optimizer)\n","\n","# Combined model (Generator + Discriminator)\n","discriminator.trainable = False\n","generated_image = generator([text_embedding_input, latent_input])\n","validity = discriminator([generated_image, text_embedding_input])\n","combined = Model(inputs=[text_embedding_input, latent_input], outputs=validity)\n","combined.compile(loss='binary_crossentropy', optimizer=generator_optimizer)\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4855355,"sourceId":8196933,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
